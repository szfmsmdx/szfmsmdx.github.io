<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>129场双周赛&amp;&amp;395场周赛</title>
    <url>/2024/04/29/129%E5%9C%BA%E5%8F%8C%E5%91%A8%E8%B5%9B-395%E5%9C%BA%E5%91%A8%E8%B5%9B/</url>
    <content><![CDATA[<p>补一下这周打的两场周赛的题。。。</p>
<span id="more"></span>
<h1 id="场双周赛">129场双周赛</h1>
<p><a
href="https://leetcode.cn/problems/find-all-possible-stable-binary-arrays-ii/description/">题目链接</a></p>
<blockquote>
<p>给你 3 个正整数 <code>zero</code> ，<code>one</code> 和
<code>limit</code> 。</p>
<p>一个二进制数组 <code>arr</code> 如果满足以下条件，那么我们称它是
<strong>稳定的</strong> ：</p>
<ul>
<li>0 在 <code>arr</code> 中出现次数 <strong>恰好</strong> 为
<code>zero</code> 。</li>
<li>1 在 <code>arr</code> 中出现次数 <strong>恰好</strong> 为
<code>one</code> 。</li>
<li><code>arr</code> 中每个长度超过<code>limit</code> 的子数组都同时包含
0 和 1 。</li>
</ul>
<p>请你返回 <strong>稳定</strong> 二进制数组的 <em>总</em> 数目。</p>
<p>由于答案可能很大，将它对 <code>1e9 + 7</code> <strong>取余</strong>
后返回。</p>
</blockquote>
<p>额额笔者一开始的思考是从组合数学去做， 首先，不考虑 limit
的情况下，一共的选法应该是 <span
class="math inline">\(C_{zoro+one}^{one}\)</span>
，组合数用杨辉三角就可以做</p>
<p>然后考虑 limit 的情况，只要减去不合法的情况即可</p>
<p>那么也就是说，选取 [limit + 1， max(zero, one)] 个连续的 1 或
0，这些都是不合法的，选完后整体法看作一个整体再插入这个数组中，但是没做出来</p>
<p>！！！错的地方在于</p>
<p>比如 limit = 1 时，选取了 2
个连续的0，这显然是不合法的，但是如果这两个被看作整体和另一个0构成了三个不合法的0，这是与取连续三个0相冲突的，所以应该用容斥原理去考虑。。。</p>
<p>虽然最后一点时间发现了问题但是已经没有时间作修改了。。。</p>
<hr />
<p>来看看正解吧，首先应该是一个经典的dp问题？原因是我们可以拆分成子规模的问题，比如说，我们记合法的数应该是
dfs(i, j, k) ，其中i、j、k分别表示0的个数、1的个数和最后一位是0还是1</p>
<p>那么举个例子，dfs(i, j, 0) 应该由 dfs(i-1, j, 0) 和 dfs(i-1, j, 1)
给出</p>
<p>但是考虑到 dfs(i-1,j,0) 表示的意义是 i-1
个0，j个1，最后一位是0，那么就有可能已经出现了连续 limit
个的情况，那么这时候，状态转移到 dfs(i, j, 0)
时，末尾再添一个0就爆了</p>
<p>==所以要排除连续 limit 个 0 的情况== ，也就是说，我们要排除
dfs(i-1,j,0) 中末尾连续 limit 个 0的情况，由于 dfs
表示的是合法的情况，所以既然末尾已经是 limit
个了，那么已经达到上限，所以倒数第 limit + 1
个位置一定是1，总的方案也应该是dfs(i-1-limit, j , 1)</p>
<p>所以 dfs(i, j, 0) = dfs(i-1,j,0)+dfs(i-1,j,1)-dfs(i-1-limit,j,1)</p>
<p>接下来考虑以下递归的边界问题？</p>
<ul>
<li>首先是 i - 1 - limit处，如果 i &lt;= limit 那显然没有必要计算了</li>
<li>其次是只放一个数字的情况，如果 i=0 且 k=1 且 j &lt;=
limit，那么只有一种情况，只放0同理</li>
</ul>
<p>最后的递归入口为 dfs(zero, one, 0) + dfs(zero, one, 1)</p>
<p>所以给出 cpp 代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="type">unsigned</span> <span class="type">long</span> <span class="type">long</span> ull;</span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt; pii;</span><br><span class="line"><span class="keyword">typedef</span> vector&lt;<span class="type">int</span>&gt; vi;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> mod = <span class="number">1e9</span> + <span class="number">7</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> INF = <span class="number">0x3f3f3f3f</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;array&lt;<span class="type">int</span>, 2&gt;&gt;&gt; memo;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">dfs</span><span class="params">(<span class="type">int</span> i, <span class="type">int</span> j, <span class="type">int</span> l, <span class="type">int</span> k)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(i == <span class="number">0</span>) <span class="keyword">return</span> j &lt;= l &amp;&amp; k == <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span>(j == <span class="number">0</span>) <span class="keyword">return</span> i &lt;= l &amp;&amp; k == <span class="number">0</span>;</span><br><span class="line">        <span class="type">int</span> &amp;res = memo[i][j][k];   <span class="comment">// 取引用;</span></span><br><span class="line">        <span class="keyword">if</span>(res != <span class="number">-1</span>) <span class="keyword">return</span> res;</span><br><span class="line">        <span class="keyword">if</span>(k == <span class="number">0</span>)&#123;</span><br><span class="line">            res = ((ll)<span class="built_in">dfs</span>(i<span class="number">-1</span>,j,l,<span class="number">0</span>)+<span class="built_in">dfs</span>(i<span class="number">-1</span>,j,l,<span class="number">1</span>)+(i&gt;l?mod-<span class="built_in">dfs</span>(i-l<span class="number">-1</span>,j,l,<span class="number">1</span>):<span class="number">0</span>))%mod;</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            res = ((ll)<span class="built_in">dfs</span>(i,j<span class="number">-1</span>,l,<span class="number">0</span>)+<span class="built_in">dfs</span>(i,j<span class="number">-1</span>,l,<span class="number">1</span>)+(j&gt;l?mod-<span class="built_in">dfs</span>(i,j-l<span class="number">-1</span>,l,<span class="number">0</span>):<span class="number">0</span>))%mod;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">numberOfStableArrays</span><span class="params">(<span class="type">int</span> zero, <span class="type">int</span> one, <span class="type">int</span> limit)</span> </span>&#123;</span><br><span class="line">        memo.<span class="built_in">resize</span>(zero+<span class="number">1</span>, vector&lt;array&lt;<span class="type">int</span>, <span class="number">2</span>&gt;&gt;(one+<span class="number">1</span>, &#123;<span class="number">-1</span>,<span class="number">-1</span>&#125;));</span><br><span class="line">        <span class="keyword">return</span> (<span class="built_in">dfs</span>(zero, one, limit, <span class="number">0</span>)%mod + <span class="built_in">dfs</span>(zero, one, limit, <span class="number">1</span>)%mod)%mod;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>观察状态转移方程：</p>
<p><span
class="math display">\[f[i][j][0]=f[i-1][j][0]+f[i-1][j][1]-f[i-limit-1][j][1]\]</span></p>
<p><span
class="math display">\[f[i][j][1]=f[i][j-1][0]+f[i][j-1][1]-f[i][j-limit-1][0]\]</span></p>
<p>于是我们可以改写成递推写法，稍微高效一些。。。</p>
<p>代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="type">unsigned</span> <span class="type">long</span> <span class="type">long</span> ull;</span><br><span class="line"><span class="keyword">typedef</span> <span class="type">long</span> <span class="type">long</span> ll;</span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="type">int</span>, <span class="type">int</span>&gt; pii;</span><br><span class="line"><span class="keyword">typedef</span> vector&lt;<span class="type">int</span>&gt; vi;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> mod = <span class="number">1e9</span> + <span class="number">7</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> INF = <span class="number">0x3f3f3f3f</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">numberOfStableArrays</span><span class="params">(<span class="type">int</span> zero, <span class="type">int</span> one, <span class="type">int</span> limit)</span> </span>&#123;</span><br><span class="line">        vector&lt;vector&lt;array&lt;<span class="type">int</span>, 2&gt;&gt;&gt; <span class="built_in">f</span>(zero + <span class="number">1</span>, vector&lt;array&lt;<span class="type">int</span>, <span class="number">2</span>&gt;&gt;(one + <span class="number">1</span>, &#123;<span class="number">0</span>, <span class="number">0</span>&#125;));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= <span class="built_in">min</span>(limit, one); ++i) f[<span class="number">0</span>][i][<span class="number">1</span>] = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= <span class="built_in">min</span>(limit, zero); ++i) f[i][<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= zero; ++i)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">1</span>; j &lt;= one; ++j)&#123;</span><br><span class="line">                f[i][j][<span class="number">0</span>] = ((ll)f[i<span class="number">-1</span>][j][<span class="number">0</span>]+f[i<span class="number">-1</span>][j][<span class="number">1</span>] + (i&gt;limit? mod - f[i-limit<span class="number">-1</span>][j][<span class="number">1</span>] : <span class="number">0</span>))%mod;</span><br><span class="line">                f[i][j][<span class="number">1</span>] = ((ll)f[i][j<span class="number">-1</span>][<span class="number">0</span>]+f[i][j<span class="number">-1</span>][<span class="number">1</span>] + (j&gt;limit? mod - f[i][j - limit - <span class="number">1</span>][<span class="number">0</span>] : <span class="number">0</span>))%mod;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> (f[zero][one][<span class="number">0</span>]+f[zero][one][<span class="number">1</span>])%mod;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h1 id="场周赛">395场周赛</h1>
<p><a
href="https://leetcode.cn/problems/find-the-median-of-the-uniqueness-array/description/">题目连接在这里</a></p>
<blockquote>
<p>给你一个整数数组 <code>nums</code> 。数组 <code>nums</code> 的
<strong>唯一性数组</strong> 是一个按元素从小到大排序的数组，包含了
<code>nums</code> 的所有非空子数组中不同元素的个数。</p>
<p>换句话说，这是由所有 <code>0 &lt;= i &lt;= j &lt; nums.length</code>
的 <code>distinct(nums[i..j])</code> 组成的递增数组。</p>
<p>其中，<code>distinct(nums[i..j])</code> 表示从下标 <code>i</code>
到下标 <code>j</code> 的子数组中不同元素的数量。</p>
<p>返回 <code>nums</code> <strong>唯一性数组</strong> 的
<strong>中位数</strong> 。</p>
<p><strong>注意</strong>，数组的 <strong>中位数</strong>
定义为有序数组的中间元素。如果有两个中间元素，则取值较小的那个。</p>
</blockquote>
<p>额额，应该是一个二分 + 滑窗 nlogn去解决。。。</p>
<p>首先，一共是有 <span class="math inline">\(m = \frac
{n(n+1)}2\)</span> 个子数组的（一个等差数列求和即可）</p>
<p>那么中位数的下标是 <span class="math inline">\(m-1/2\)</span>
下取整的，中位数的个数是 <span class="math inline">\(k=m + 1 /
2\)</span> 下取整也就是 <span class="math inline">\(k = m/2\)</span>
上取整了。。。</p>
<p>==！那么，只需要二分中位数，记作 upper，问题就变成了 distinct 值 &lt;
upper 的子数组有多少个== (√)</p>
<p>并且记子数组个数为 cnt ，如果 k &lt; cnt ，那么自然说明二分的 upper
小了（数组长度与 distinct 呈现单调的关系），那么就更新二分的左边界</p>
<p>那如何去计算 distinct 值小于 upper 的子数组的个数？</p>
<p>用滑窗滑一轮 O(n) 即可。。。</p>
<p>用一个哈希表 freq 统计出现的个数，枚举窗口右端点，如果 freq 大小大于
upper，那么就不断移除左端点元素（就是出现次数 -1， 如果为 0 直接从 freq
移除</p>
<p>那么一共就有 r - l + 1 个子数组</p>
<p>代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">medianOfUniquenessArray</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> n = nums.<span class="built_in">size</span>();</span><br><span class="line">        ll k = ((ll)n * (n + <span class="number">1</span>) / <span class="number">2</span> + <span class="number">1</span>) / <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">auto</span> check = [&amp;](<span class="type">int</span> upper)&#123;</span><br><span class="line">            ll cnt = <span class="number">0</span>;</span><br><span class="line">            <span class="type">int</span> l = <span class="number">0</span>;</span><br><span class="line">            unordered_map&lt;<span class="type">int</span>, <span class="type">int</span>&gt; freq;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> r = <span class="number">0</span>; r &lt; n; ++r)&#123;</span><br><span class="line">                freq[nums[r]] ++;</span><br><span class="line">                <span class="keyword">while</span>(freq.<span class="built_in">size</span>() &gt; upper)&#123;</span><br><span class="line">                    <span class="type">int</span> out = nums[l++];</span><br><span class="line">                    <span class="keyword">if</span>(--freq[out] == <span class="number">0</span>)&#123;</span><br><span class="line">                        freq.<span class="built_in">erase</span>(out);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                cnt += r - l + <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">if</span>(cnt &gt;= k)&#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> left = <span class="number">0</span>, right = n;</span><br><span class="line">        <span class="keyword">while</span>(left + <span class="number">1</span>&lt; right)&#123;</span><br><span class="line">            <span class="type">int</span> mid = (left + right) / <span class="number">2</span>;</span><br><span class="line">            (<span class="built_in">check</span>(mid) ? right : left) = mid;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> right;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>DP</tag>
        <tag>周赛</tag>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>花书——机器学习基础</title>
    <url>/2024/04/28/%E8%8A%B1%E4%B9%A6%E2%80%94%E2%80%94%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>研读花书，皆为拙记，如有错误还望各位不惜笔墨，不啬赐教。本节主要包括<strong>机器学习基础</strong>部分内容</p>

</blockquote>
<span id="more"></span>
<blockquote>
<p>机器学习本质上属于应用统计学，更多地关注于如何用
计算机统计地估计复杂函数，不太关注为这些函数提供置信区间；因此我们会探讨两种统计学的主要方法：<strong>频率派估计</strong>和贝叶斯推断。</p>
</blockquote>
<p>大部分机器学习算法可以分为：</p>
<ul>
<li>监督学习：数据点都有一个<strong>标签（label）</strong>或者<strong>目标（target）</strong></li>
<li>无监督学习：从含有多特征的数据集中学习出这个数据集上有用的结构性质</li>
</ul>
<p>花书大部分的优化器都是采用的SGD对问题进行求解、计算的</p>
<h1 id="学习算法">学习算法</h1>
<p>机器学习算法是一种能够从数据中学习的算法。然而，我们所谓的 ‘‘学习’’
是什么意思呢？Mitchell (1997) 提供了一个简洁的定义：‘‘对于某类任务 T
和性能度量 P，一个计算机程序被认为可以从经验 E 中学习是指，通过经验 E
改进后，它在任务 T 上由性能度量 P 衡量的性能有所提升。”</p>
<h2 id="任务t">任务T</h2>
<p>通常机器学习任务定义为机器学习系统应该如何处理
<strong>样本（example）</strong></p>
<p>样本是
指我们从某些希望机器学习系统处理的对象或事件中收集到的已经量化的
<strong>特征 （feature）</strong>的集合。通常用一个向量 <span
class="math inline">\(\vec x\)</span> 来表示，其中 <span
class="math inline">\(x_i\)</span> 表示的是不同的特征</p>
<p>一般来说，常见的机器学习任务列举如下：</p>
<ul>
<li>分类</li>
<li>输入缺失型分类：通常不是学习某一个而是<strong>一组</strong>函数，每个函数对应着分类具有不同缺失输入子集，比如输入特征为n个，那么一共的缺失输入集合总数量就可能来到了<span
class="math inline">\(2^n\)</span></li>
<li>回归</li>
<li>机器翻译：输入是一种语言的符号序列，计算机程序需要将其转化为另一种语言的符号与劣，通常适用于NLP</li>
<li>结构化输出：结构化输出任务的输出是向量或者其他包含多个值的数据结构，
并且构成输出的这些不同元素间具有重要关系。例如语法分析——映射自然语言句子到语法结构树，并标记树的节点为动词、名词、副词等等。</li>
<li>异常检测</li>
<li>合成和采样：在这类任务中，机器学习程序生成一些和训练数据相似的新样本。==这是一类结构化输出任务，但是多了每个输入并非只有一个正确输出的
条件，并且我们明确希望输出有很多变化，这可以使结果看上去更加自然和真实。==</li>
<li>缺失值填补</li>
<li>去噪：（个人感觉有些类似于异常检测。。。</li>
</ul>
<h2 id="性能度量p">性能度量P</h2>
<p>对于诸如分类、缺失输入分类和转录任务，我们通常度量模型的
<strong>准确率（accuracy）</strong>
。通常，我们会更加关注机器学习算法在未观测数据上的性能如何，因为这将决
定其在实际应用中的性能。因此，我们使用 测试集（test
set）数据来评估系统性能， 将其与训练机器学习系统的训练集数据分开。</p>
<p>==性能度量的选择或许看上去简单且客观，但是选择一个与系统理想表现对应
的性能度量通常是很难的。==</p>
<p>在某些情况下，这是因为很难确定应该度量什么。例如，在执行转录任务时，我
们是应该度量系统转录整个序列的准确率，还是应该用一个更细粒度的指标，对序
列中正确的部分元素以正面评价？在执行回归任务时，我们应该更多地惩罚频繁犯一些中等错误的系统，还是较少犯错但是犯很大错误的系统？这些设计的选择取决
于应用。</p>
<h2 id="经验e">经验E</h2>
<p>本书中的大部分学习算法可以被理解为在整个
<strong>数据集（dataset）</strong>上获取经验。</p>
<p>大致说来，无监督学习涉及到观察随机向量 x 的好几个样本，试图显式或隐式
地学习出概率分布
p(x)，或者是该分布一些有意思的性质；而监督学习包含观察随 机向量 x
及其相关联的值或向量 y，然后从 x 预测 y，通常是估计 p(y | x)。</p>
<blockquote>
<p>无监督学习和监督学习不是严格定义的术语。它们之间界线通常是模糊的。很
多机器学习技术可以用于这两个任务。例如，概率的链式法则表明对于向量<span
class="math inline">\(x \in \mathbb R^n\)</span> ，联合分布可以分解成
<span class="math display">\[
p(x)=\Pi_{i=1}^n p(x_i|x_1,x_2,\cdots,x_{i-1})
\]</span></p>
<p>该分解意味我们可以将其拆分成 n
个监督学习问题，来解决表面上的无监督学习 p(x)。另外，求解监督学习问题
p(y|x) 时，也可以使用传统的无监督学习策略学习联合分布 p(x, y) ，然后推断
<span class="math inline">\(p(y|\mathrm x)=\frac{p(\mathrm x,
y)}{\sum_{y&#39;}p(\mathrm x, y&#39;)}\)</span>​</p>
</blockquote>
<p>尽管无监督学习和监督学习并非完全没有交集的正式概念，它们确实有助于粗略分
类我们研究机器学习算法时遇到的问题。传统地，人们将回归、分类或者结构化输
出问题称为监督学习。支持其他任务的密度估计通常被称为无监督学习。</p>
<p>学习范式的其他变种也是有可能的。例如，半监督学习中，一些样本有监督目
标，但其他样本没有。在多实例学习中，样本的整个集合被标记为含有或者不含有
该类的样本，但是集合中单独的样本是没有标记的。</p>
<p>有些机器学习算法并不是训练于一个固定的数据集上。例如，
<strong>强化学习（reinforcement
learning）</strong>算法会和环境进行交互，所以学习系统和它的训练过程会有反
馈回路。</p>
<p>表示数据集的常用方法是 <strong>设计矩阵（design
matrix）</strong>。设计矩阵的每一行包含
一个不同的样本。每一列对应不同的特征。</p>
<h1 id="容量过拟合与欠拟合">容量、过拟合与欠拟合</h1>
<p>机器学习的主要挑战是我们的算法必须能够在先前未观测的新输入上表现良好，
而不只是在训练集上表现良好。在先前未观测到的输入上表现良好的能力被称为
<strong>泛化（generalization）</strong>。</p>
<p>通常情况下，当我们训练机器学习模型时，我们可以使用某个训练集，在训练
集上计算一些被称为 <strong>训练误差（training
error）</strong>的度量误差，目标是降低训练误差。同时，我们在降低训练误差的过程中也希望<strong>泛化误差（generalization
error）</strong>很低</p>
<p>训练集和测试集数据通过数据集上被称为 <strong>数据生成过程（data
generating
process）</strong>的概率分布生成。通常，我们会做一系列被统称为
<strong>独立同分布假设（i.i.d.
assumption）</strong>的假设。该假设是说，每个数据集中的样本都是彼此
<strong>相互独立的（independent）</strong>，并且训练集和测试集是
<strong>同分布的（identically
distributed）</strong>，采样自相同的分布。这个假设使我们能够在单个样本的概率分布描述数据生成过程。然后相同的分布可以用来生成每一个训练样本和每一个测试样本。我们将这个共享的潜在
分布称为 <strong>数据生成分布（data generating
distribution）</strong>，记作 <span
class="math inline">\(p_{data}\)</span> 。</p>
<p>我们能观察到训练误差和测试误差之间的直接联系是，<strong>随机模型训练误差的期望和该模型测试误差的期望是一样的</strong>。我们采样得到训练集，然后挑选参数去降低训练集误差，然后采样得到测试集。在这个过程中，<strong>测试误差期望会大于或等于训练误差期望</strong>。以下是决定机器学习算法效果是否好的因素：</p>
<ol type="1">
<li>降低训练误差</li>
<li>缩小训练误差和测试误差的差距</li>
</ol>
<p>这两个因素对应机器学习的两个主要挑战：</p>
<ul>
<li><strong>欠拟合（underfitting）</strong>：模型不能在训练集上获得足够低的误差</li>
<li><strong>过拟合
（overfitting）</strong>：训练误差和测试误差之间的差距太大</li>
</ul>
<p>通过调整模型的
<strong>容量（capacity）</strong>，我们可以控制模型是否偏向于过拟合或者欠
拟合。通俗地，模型的容量是<strong>指其拟合各种函数的能力</strong>。容量低的模型可能很难拟合训练集；容量高的模型可能会过拟合，因为记住了不适用于测试集的训练集性质。</p>
<p>一种控制训练算法容量的方法是选择 <strong>假设空间（hypothesis
space）</strong>，即学习算法可以选择为解决方案的函数集。例如，线性回归算法将关于其输入的所有线性函数作为假设空间。广义线性回归的假设空间包括多项式函数，而非仅有线性函数。这样做就增加了模型的容量。</p>
<p>一次多项式<span class="math inline">\(\hat y=b+wx\)</span> 通过引入
<span class="math inline">\(x^2\)</span>
作为线性回归模型的另一个特征，我们能够学习到 x 的二次函数模型 <span
class="math inline">\(\hat y=b+w_1x+w_2x^2\)</span>
。尽管该模型是输入的二次函数，但输出仍是参数的线性函数。</p>
<p>当机器学习算法的容量适合于所执行任务的复杂度和所提供训练数据的数量时，
算法效果通常会最佳。容量不足的模型不能解决复杂任务。容量高的模型能够解决
复杂的任务，但是当其容量高于任务所需时，有可能会过拟合。</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051408206.png" alt="image-20240505140857160" style="zoom:50%;" /></p>
<p>模型规定了调整参数降低训练目标时，学习算法可以从哪些函数族中选择函数。这被称为模型的
<strong>表示容量（representational capacity）</strong>
。在很多情况下，从这些函数中挑选出最优函数是非常困难的优化问题。实际中，学习算法不会真的找到最优函数，而仅是找到一个可以大大降低训练误差的函数。额外的限制因素，比如优化算法的不完美，意味着学习算法的
<strong>有效容量（effective
capacity）</strong>可能小于模型族的表示容量。</p>
<hr />
<p><strong>奥卡姆剃刀（Occam‘s
razor）</strong>原则：在同样能够解释已知观测现象的假设中，我们 应该挑选
‘‘最简单’’ 的那一个。</p>
<p>统计学习理论提供了量化模型容量的不同方法。在这些中，最有名的是
<strong>VapnikChervonenkis 维度（Vapnik-Chervonenkis dimension,
VC）</strong>。VC维定义为该分类器<strong>能够分类的训练样本的最大数目</strong>。</p>
<p>假设存在 m 个不同 x 点的训练集，分类器可以任意地标记该 m 个不同的 x
点，VC维被定义为 m 的最大可能值</p>
<p>参见<a
href="https://tangshusen.me/2018/12/09/vc-dimension/#comments">这篇文章</a>对
VC 维的推导</p>
<p>简单来说，在该模型对应的空间中随机撒x点，然后对其中的每个点随机分配一个2类标签，使用你的模型来分类，并且要分对，请问x至多是多少。这个x就是VC维。</p>
<p>比如对于线性函数来说：</p>
<p>如果是二维空间里的线性函数的话，那么他的VC维应该是3，因为对于4个点，存在一种情况不管用什么直线都无论如何做不到完全分类的</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051445577.png" alt="image-20240505144512543" style="zoom:50%;" /></p>
<p>如果选择三维空间的线性函数的话，那么该模型的VC维应该是4</p>
<p>所以VC维越大，也就是说他能够包含的情况越多，假设空间大，也就是他的容量大</p>
<hr />
<p>我们必须记住虽然更简单的函数更可能泛化，但我们仍然需要选择一个充分复杂的假设以达到低的训练误差。</p>
<p>通常，当模型容量上升时，训练误差会下降，直到其渐近最小可能误差（假设误差度量有最小值）。通常，泛化误差是一个关于模型容量的
U 形曲线函数。</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051450234.png" alt="image-20240505145055192" style="zoom:60%;" /></p>
<p>为考虑容量任意高的极端情况，我们介绍
<strong>非参数（non-parametric）</strong>模型的概念。有时，非参数模型仅是一些不能实际实现的理论抽象（比如搜索所有可能概率分布的算法）。然而，我们也可以设计一些实用的非参数模型，使它们的复杂度和训练集大小有关。</p>
<h2 id="没有免费午餐定理">没有免费午餐定理</h2>
<p>机器学习的 <strong>没有免费午餐定理（no free lunch
theorem）</strong>表明 (Wolpert,
1996)，在所有可能的数据生成分布上平均之后，每一个分类算法在未事先观测的点上都有相同的错误率。换言之，在某种意义上，没有一个机器学习算法总是比其他的要好。我们能够设想的最先进的算法和简单地将
所有点归为同一类的简单算法有着相同的平均性能（在所有可能的任务上）。</p>
<h2 id="正则化">正则化</h2>
<p>没有免费午餐定理暗示我们必须在特定任务上设计性能良好的机器学习算法。</p>
<p>算法的效果不仅很大程度上受影响于假设空间的函数数量，也取决于这些函数
的具体形式。例如，我们用线性回归，从 x 预测
sin(x)，效果不会好。因此我们可以通过两种方式控制算法的性能：</p>
<ol type="1">
<li>允许使用的函数种类</li>
<li>这些函数的数量</li>
</ol>
<p>在假设空间中，相比于某一个学习算法，我们可能更偏好另一个学习算法。这
意味着两个函数都是符合条件的，但是我们更偏好其中一个。只有非偏好函数比偏
好函数在训练数据集上效果明显好很多时，我们才会考虑非偏好函数。</p>
<p>例如，我们可以加入 <strong>权重衰减（weight
decay）</strong>来修改线性回归的训练标准。带权重衰减的线性回归最小化训练集上的均方误差和正则项的和
J(w)，其偏好于平方 <span class="math inline">\(L_2\)</span>
范数较小的权重。具体如下： <span class="math display">\[
J(w)=\mathrm {MSE}_{\mathrm {train}}+\lambda w^T w
\]</span></p>
<p>其中 λ 是提前挑选的值，控制我们偏好小范数权重的程度。当 λ =
0，我们没有任何偏好。越大的 λ 偏好范数越小的权重。</p>
<p>更一般地，正则化一个学习函数 f(x; θ)
的模型，我们可以给代价函数添加被称为
<strong>正则化项（regularizer）</strong>的惩罚。在权重衰减的例子中，正则化项是
<span class="math inline">\(\Omega(w)=w^T w\)</span></p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051511901.png" alt="image-20240505151147854" style="zoom:67%;" /></p>
<p>在我们权重衰减的示例中，通过在最小化的目标中额外增加一项，我们明确地表示了偏好权重较小的线性函数。有很多其他方法隐式或显式地表示对不同解的偏好。总而言之，这些不同的方法都被称为
<strong>正则化（regularization）</strong>。正则化是指我们修改学习算法，使其降低<strong>泛化误差</strong>而<strong>非训练误差</strong>。</p>
<h1 id="超参数和验证集">超参数和验证集</h1>
<p>参考了<a
href="https://blog.csdn.net/qq_24884193/article/details/104071664">这篇文章</a></p>
<p>几个数据集的辨析。。。</p>
<ul>
<li>训练集：训练集用来训练模型，即确定模型的权重和偏置这些参数，通常我们称这些参数为学习参数。</li>
<li>测试集：与训练集同分布的样本组成，只使用一次，即在训练完成后评价最终的模型时使用。</li>
<li>验证集：为了挑选超参数，比如网络层数、网络节点数、迭代次数、学习率这些都叫超参数。</li>
</ul>
<p>通常，80% 的训练数据用于训练，20% 用于验证。由于验证集是用来 ‘‘训练’’
超参数的，尽管验证集的误差通常会比训练集误差小，验证集会低估泛化误差。所有超参数优化完成之后，泛化误差可能会通过测试集来估计。</p>
<figure>
<img
src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051521597.png"
alt="image-20240505152122552" />
<figcaption aria-hidden="true">image-20240505152122552</figcaption>
</figure>
<h2 id="交叉验证">交叉验证</h2>
<p>之所以出现交叉验证，主要是因为训练集较小。无法直接像前面那样只分出训练集，验证集，测试就可以了（简单交叉验证）。</p>
<p>需要说明的是，在实际情况下，<u>人们不是很喜欢用交叉验证</u>，主要是因为它会<strong>耗费较多的计算资源</strong>。一般直接把训练集按照50%-90%的比例分成训练集和验证集。但这也是根据具体情况来定的：如果超参数数量多，你可能就想用更大的验证集，而验证集的数量不够，那么最好还是用交叉验证吧。至于分成几份比较好，一般都是分成3、5和10份。</p>
<figure>
<img
src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051523070.png"
alt="image-20240505152339013" />
<figcaption aria-hidden="true">image-20240505152339013</figcaption>
</figure>
<p>假设将训练集分成5份（该数目被称为折数，5-fold交叉验证），每次都用其中4份来训练模型，粉红色的那份用来验证4份训练出来的模型的准确率，记下准确率。</p>
<p><code>然后再次在这5份中取另外4份做训练集，1份做验证集，再次得到一个模型的准确率</code></p>
<p>(五选四的话，只用做五遍就ok了)
直到所有5份都做过1次验证集，也即验证集名额循环了一圈，交叉验证的过程就结束。算得这5次准确率的均值。留下准确率最高的模型，即该模型的超参数是什么样的最终模型的超参数就是这个样的。</p>
<h1 id="最大似然估计">最大似然估计</h1>
<p>考虑一组含有 m 个样本的数据集 <span class="math inline">\(\mathbb
X=\{x^{(1)},\cdots,x^{(m)}\}\)</span> ，独立地由未知的真实数据生成分布
<span class="math inline">\(p_{data}(\mathrm x)\)</span> 生成</p>
<p>令 <span class="math inline">\(p_{model}(\mathrm x;\theta)\)</span>
是一族<strong>由 <span class="math inline">\(\theta\)</span>
确定在相同空间上的概率分布</strong>。换言之， <span
class="math inline">\(p_{model}(x;\theta)\)</span> 将任意输入 x
映射到实数来估计真实概率 <span
class="math inline">\(p_{data}(x)\)</span></p>
<p>对 θ 的最大似然估计被定义为：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051542138.png" alt="image-20240505154225093" style="zoom:50%;" /></p>
<p>多个概率的乘积会因很多原因不便于计算。例如，计算中很可能会出现数值下溢。为了得到一个便于计算的等价优化问题，我们观察到似然对数不会改变其
arg max 但是将乘积转化成了便于计算的求和形式：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051545774.png" alt="image-20240505154529731" style="zoom:50%;" /></p>
<blockquote>
<p>一种解释最大似然估计的观点是将它看作最小化训练集上的经验分布 <span
class="math inline">\(\hat p_{data}\)</span>
和模型分布之间的差异，两者的差异程度可以通过KL散度衡量。即 <span
class="math inline">\(D_{KL}(\hat p_{data} || p_{model})=\mathbb
E_{\mathrm x  \sim \hat p_{model}}[\log \hat p_{data}(x)-\log
p_{model}(x)]\)</span></p>
<p>左边一项仅涉及到数据生成过程，和模型无关。这意味着当我们训练模型最小化
KL散度时，我们只需要最小化<span class="math inline">\(-\mathbb
E_{\mathrm x  \sim \hat p_{model}}[\log p_{model}(x)]\)</span></p>
</blockquote>
<h2 id="条件对数似然和均方误差">条件对数似然和均方误差</h2>
<p>最大似然估计很容易扩展到估计条件概率 <span
class="math inline">\(P(\mathrm y|\mathrm x;\theta)\)</span> ，从而给定
x 预测 y。实际上这是最常见的情况，因为这构成了大多数监督学习的基础。如果
X 表示所有的输入，Y 表示我们观测到的目标，那么条件最大似然估计是 <span
class="math inline">\(\theta_{ML}=\mathrm {arg}\max_\theta
P(Y|X;\theta)\)</span> 如果假设样本是独立同分布的，那么这可以分解成
<span class="math display">\[
\theta_{ML}=\mathrm{arg}\max_\theta \sum_{i=1}^m \log
P(y^{(i)}|x^{(i)};\theta)
\]</span> 在最大似然的角度下重新审视线性回归，在假设样本是
i.i.d，那么条件对数似然如下：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051602846.png" alt="image-20240505160206791" style="zoom:67%;" /></p>
<p>其中 <span class="math inline">\(y^{(i)}\)</span>​ 是线性回归在第 i
个输入 x (i) 上的输出，m 是训练样本的数目。对比均方 误差和对数似然</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051602712.png" alt="image-20240505160242665" style="zoom:67%;" /></p>
<h2 id="最大似然的性质">最大似然的性质</h2>
<p>最大似然估计最吸引人的地方在于，它被证明当样本数目 <span
class="math inline">\(m\to \infty\)</span>
时，就收敛率而言是最好的渐近估计。</p>
<p>在合适的条件下，最大似然估计具有一致性，意味着训练样本数目趋向于无穷大时，参数的最大似然估计会收敛到参数的真实值。这些条件是：</p>
<ul>
<li>真实分布 <span class="math inline">\(p_{data}\)</span> 必须在模型族
<span class="math inline">\(p_{model}(·;\theta)\)</span>
中。否则，没有估计可以还原 <span
class="math inline">\(p_{data}\)</span></li>
<li>真实分布 <span class="math inline">\(p_{data}\)</span>
必须刚好对应一个 θ 值。否则，最大似然估计恢复出真实分布 <span
class="math inline">\(p_{data}\)</span>
后，也不能决定数据生成过程使用哪个 θ。</li>
</ul>
<h1 id="贝叶斯统计">贝叶斯统计</h1>
<blockquote>
<p>老实说这块我学的云里雾里，有时间会好好学一遍贝叶斯统计。。。</p>
</blockquote>
<p>至此我们已经讨论了 <strong>频率派统计（frequentist
statistics）</strong>方法和基于估计单一值 θ
的方法，然后基于该估计作所有的预测。另一种方法是在做预测时会考虑所有可能的
θ。后者属于 <strong>贝叶斯统计（Bayesian
statistics）</strong>的范畴。</p>
<p>贝叶斯用概率反映知识状态的确定性程度。数据集能够被直接观测到，因此不是随机的。另一方面，真实参数
θ 是未知或不确定的，因此可以表示成随机变量。</p>
<p>在观察到数据前，我们将 θ 的已知知识表示成 <strong>先验概率分布（prior
probability distribution）</strong>，p(θ)（有时简单地称为
‘‘先验’’）。一般而言，机器学习实践者会选择一个相当宽泛的（即，高熵的）先验分布，反映在观测到任何数据前参数
θ 的高度不确定性。例如，我们可能会假设先验 θ
在有限区间中均匀分布。<strong>许多先验偏好于‘‘更简单’’
的解</strong>（如小幅度的系数，或是接近常数的函数）。</p>
<p>假设我们有一组数据样本 <span
class="math inline">\(\{x^{(1)},\cdots,x^{(m)}\}\)</span>，通过贝叶斯规则结合数据似然
<span class="math inline">\(p(x^{(1)},\cdots,x^{(m)}|\theta)\)</span>
和先验，我们可以恢复数据对我们关于 θ 信念的影响：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051626129.png" alt="image-20240505162658072" style="zoom: 50%;" /></p>
<p>在贝叶斯估计常用的情景下，先验开始是相对均匀的分布或高熵的高斯分布，观测数据通常会使后验的熵下降，并集中在参数的几个可能性很高的值。</p>
<p>相对于最大似然估计，贝叶斯估计有两个重要区别。<strong>第一</strong>，不像最大似然方法预测时使用
θ 的点估计，贝叶斯方法使用 θ 的全分布。例如，在观测到 m
个样本后，下一个数据样本 x (m+1) 的预测分布如下：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051631677.png" alt="image-20240505163108624" style="zoom: 50%;" /></p>
<p>这里，每个具有正概率密度的 θ
的值有助于下一个样本的预测，其中贡献由后验密度本身加权。在观测到数据集
<span class="math inline">\(\{x^{(1)},\cdots,x^{(m)}\}\)</span>
之后，如果我们仍然非常不确定 θ
的值，那么这个不确定性会直接包含在我们所做的任何预测中。</p>
<p>贝叶斯方法和最大似然方法的<strong>第二</strong>个最大区别是由贝叶斯先验分布造成的。先验能够影响<strong>概率质量密度朝参数空间中偏好先验的区域偏移</strong>。实践中，先验通常表现为偏好更简单或更光滑的模型。对贝叶斯方法的批判认为先验是人为主观判断影响预测的来源。</p>
<blockquote>
<p>当训练数据很有限时，贝叶斯方法通常泛化得更好，但是当训练样本数目很大时，通常会有很大的计算代价。</p>
</blockquote>
<h3 id="贝叶斯线性回归">贝叶斯线性回归</h3>
<p>使用贝叶斯估计方法学习线性回归的参数</p>
<p>在线性回归中，我们学习从输入向量 <span class="math inline">\(x\in
\mathbb R^n\)</span> 预测标量 <span class="math inline">\(y\in
R\)</span> 的线性映射。该预测由向量 <span class="math inline">\(w\in
\mathbb R^n\)</span> 参数化：<span class="math inline">\(\hat y=w^T
x\)</span></p>
<p>给定一组 m 个训练样本 <span
class="math inline">\((X^{(train)},y^{(train)})\)</span>
可以表示整个训练集对 y 的预测： <span class="math inline">\(\hat
y^{(train)}=X^{(train)} w\)</span> 表示为<span
class="math inline">\(y^{(train)}\)</span> 上的高斯条件分布</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051645107.png" alt="image-20240505164530045" style="zoom: 50%;" /></p>
<p>其中，我们根据标准的 MSE 公式假设 y 上的高斯方差为
1。为确定模型参数向量 w
的后验分布，我们首先需要指定一个先验分布。实数值参数通常使用高斯作为先验分布：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051647077.png" alt="image-20240505164730017" style="zoom:50%;" /></p>
<p>其中，<span class="math inline">\(\mu_0\)</span> 和 <span
class="math inline">\(\Lambda_0\)</span>
分别是先验分布的均值向量和协方差矩阵。</p>
<p>确定好先验后，我们现在可以继续确定模型参数的后验分布。</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051649351.png" alt="image-20240505164924280" style="zoom: 50%;" /></p>
<p>现在我们定义 <span class="math inline">\(\Lambda_m=(X^T
X+\Lambda_0^{-1})^{-1}\)</span> 和 <span
class="math inline">\(\mu_m=\Lambda_m(X^T
y+\Lambda_0^{-1}\mu_0)\)</span>
，利用新变量可以将后验改写为高斯分布：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202405051652868.png" alt="image-20240505165252802" style="zoom:50%;" /></p>
<p>大多数情况下，我们设置 <span class="math inline">\(\mu_0=0\)</span>
。如果我们设置 <span class="math inline">\(\Lambda_0=\frac 1\alpha
I\)</span> ，那么 <span class="math inline">\(\mu_m\)</span> 对 w
的估计就和频率派带权重衰减惩罚 <span class="math inline">\(\alpha w^T
w\)</span>​ 的线性回归的估计是一样的。</p>
<h2 id="最大后验map估计">最大后验（MAP）估计</h2>
<p>原则上，我们应该使用参数 θ
的完整贝叶斯后验分布进行预测，但单点估计常常也是需要的。MAP
估计选择后验概率最大的点（或在 θ
是连续值的更常见情况下，概率密度最大的点）：</p>
<p><span class="math display">\[\theta_\mathrm {MAP}=\mathrm {arg}
\max_\theta p(\theta | x)=\mathrm {arg}\max_\theta \log p(x|\theta)+\log
p(\theta)\]</span></p>
<p>我们可以认出上式右边的 <span class="math inline">\(\log
p(x|\theta)\)</span> 对应着标准的对数似然项，<span
class="math inline">\(\log p(\theta)\)</span> 对应先验分布</p>
<h1 id="监督学习算法">监督学习算法</h1>
<p>粗略地说，监督学习算法是给定一组输入 x 和输出 y
的训练集，学习如何关联输入和输出。很多情况下， 由于 y
很难自动收集，需要人来提供“监督”（不过该术语仍然适用于训练集目标可以被自动收集的情况</p>
<h2 id="概率监督学习">概率监督学习</h2>
<p>花书大部分监督学习算法都是基于估计概率分布 <span
class="math inline">\(p(y|\mathrm x)\)</span>
的，可以使用最大似然估计找到对于有参分布族 <span
class="math inline">\(p(y|\mathrm x;\theta)\)</span> 最好的参数向量
<span class="math inline">\(\theta\)</span></p>
<p>显然线性回归对应分布族为 <span
class="math inline">\(p(y|x;\theta)=\mathcal N(y;\theta^T
x,I)\)</span></p>
<p>我们用于线性回归的实数正态分布是用均值参数化的。二元变量上的分布稍微复杂些，因为它的均值必须始终在
0 和 1之间。解决这个问题的一种方法是使用 logistic sigmoid
函数将线性函数的输出压缩进区间 (0, 1)。该值可以解释为概率： <span
class="math inline">\(p(y=1|x;\theta)=\sigma(\theta^T x)\)</span></p>
<p>这个方法被称为 <strong>逻辑回归（logistic
regression）</strong>这个名字有点奇怪，因为该模型用于分类而非回归。</p>
<h2 id="支持向量机">支持向量机</h2>
<p><strong>支持向量机（support vector machine,
SVM）</strong>是监督学习中最有影响力的方法之一。不同于逻辑回归的是，支持向量机不输出概率，只输出类别。当
<span class="math inline">\(w^T x+b\)</span>
为正时，支持向量机预测属于正类。类似地，当 <span
class="math inline">\(w^T+b\)</span>
为负时，支持向量机预测属于负类。</p>
<p>支持向量机的一个重要创新是 核技巧（kernel
trick）。核技巧观察到许多机器学习算法都可以写成样本间点积的形式。例如，支持向量机中的线性函数可以重写为
<span class="math display">\[
w^T x+b=b+\sum_{i=1}^m\alpha_i x^T x^{(i)}
\]</span> 其中 <span class="math inline">\(x^{(i)}\)</span>
是训练样本，<span class="math inline">\(\alpha\)</span>
是系数向量，学习算法重写为这种形式允许我们将 x 替换为特征函数 <span
class="math inline">\(\phi (x)\)</span>
的输出，点积替换为被称为核函数（kernel function）的函数 <span
class="math inline">\(k(x, x^{(i)})=\phi(x)·\phi(x^{(i)})\)</span></p>
<p>使用核估计替换点积之后，我们可以使用如下函数进行预测： <span
class="math display">\[
f(x)=b+\sum_i \alpha_i k(x,x^{(i)})
\]</span> 这个函数关于 x 是非线性的，关于 ϕ(x) 是线性的。α 和 f(x)
之间的关系也是线性的。核函数完全等价于用 ϕ(x)
预处理所有的输入，然后在新的转换空间学习线性模型。</p>
<p>核技巧有两大优势：</p>
<ol type="1">
<li>它使我们能够使用保证有效收敛的凸优化技术来学习非线性模型（关于 x
的函数）</li>
<li>核函数 k 的实现方法通常有比直接构建 ϕ(x) 再算点积高效很多。</li>
</ol>
<p>在某些情况下，<span class="math inline">\(\phi(x)\)</span>
甚至可以是无限维的，对于普通的显式方法而言，这将是无限的计算代价。在很多情况下，即使
<span class="math inline">\(\phi(x)\)</span> 是难算的，<span
class="math inline">\(k(x,x&#39;)\)</span> 却会是一个关于
x非线性的、易算的函数。假设这个映射返回一个由开头 x 个 1，随后是无限个0
的向量。我们可以写一个核函数 <span
class="math inline">\(k(x,x&#39;)=\min(x,x&#39;)\)</span>
，完全等价于对应的无限维点积。</p>
<p>最常用的核函数是 <strong>高斯核（Gaussian kernel）</strong>： <span
class="math display">\[
k(u,v)=\mathcal N(u-v;0,\sigma^2I)
\]</span> 其中 <span class="math inline">\(\mathcal
N(x;\mu,\Sigma)\)</span>​ 是标准正态密度。这个核也被称为
<strong>径向基函数（radial basis function, RBF）</strong>核，因为其值沿
v 中从 u
向外辐射的方向减小。高斯核对应于<strong>无限维空间</strong>中的点积，但是该空间的推导没有整数上最小核的示例那么直观。</p>
<p>我们可以认为高斯核在执行一种<strong>模板匹配 (template
matching)</strong>。训练标签 y 相关的训练样本 x 变成了类别 y
的模版。当测试点 x ′ 到 x
的欧几里得距离很小，对应的高斯核响应很大时，表明 x ′ 和模版 x
非常相似。该模型进而会赋予相对应的训练标签 y
较大的权重。总的来说，预测将会组合很多这种通过训练样本相似度加权的训练标签。</p>
<p>核机器的一个主要缺点是计算决策函数的成本关于训练样本的数目是线性的。因为第
i 个样本贡献 <span class="math inline">\(\alpha_i k(x,x^{(i)})\)</span>
到决策函数。支持向量机能够通过学习主要包含零的向量
α，以缓和这个缺点。那么判断新样本的类别仅需要计算非零 αi
对应的训练样本的核函数。这些训练样本被称为 <strong>支持向量（support
vector）</strong></p>
<h1 id="无监督学习算法">无监督学习算法</h1>
]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>花书</tag>
        <tag>Deep Learning</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>花书——数值计算</title>
    <url>/2024/04/27/%E8%8A%B1%E4%B9%A6%E2%80%94%E2%80%94%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>研读花书，皆为拙记，如有错误还望各位不惜笔墨，不啬赐教。本节主要包括<strong>数值计算</strong>部分内容</p>

</blockquote>
<span id="more"></span>
<blockquote>
<p>这里的数值计算通常是指通过迭代过程更新解的估计值来解决数学问题的算法，而不是通过解析过程推导出公式来提供正确解的方法</p>
<p>常见的操作包括优化（找到最小化或最大化函数值的参数）和线性方程组的求解</p>
</blockquote>
<h1 id="上溢和下溢">上溢和下溢</h1>
<p>==连续数学在数字计算机上的根本困难是，我们需要通过有限数量的位模式来表示无限多的实数==</p>
<p>这意味着我们在计算机中表示实数时，几乎总会引入一些<strong>近似误差</strong>。</p>
<ul>
<li><strong>下溢（underflow）</strong>：当接近零的数被四舍五入为
零时发生下溢。</li>
<li><strong>上溢（overflow）</strong>：当大量级的数被近似为 <span
class="math inline">\(+\infty\)</span> 或 <span
class="math inline">\(-\infty\)</span> 时发生上溢</li>
</ul>
<p>softmax函数通常用于预测与范畴分布相关联的概率，定义为：<span
class="math inline">\(\mathrm
{softmax}(x)_i=\frac{\exp(x_i)}{\sum_{j=1}^n\exp(x_j)}\)</span></p>
<p>考虑所有 x 都是常数 c 的情况，这使得所有的输出都应该是 1/n：</p>
<ul>
<li>当 c 很大时，计算 exp(c) 会爆发上溢</li>
<li>当 c 是个很小的负数时，使得 exp(c) 发生下溢，使得 exp(c)
几乎为0，那么分母就会无意义</li>
</ul>
<p>但是 softmax 在计算时可以通过 softmax(z) 来解决，其中 <span
class="math inline">\(z=x-\max_i\ x_i\)</span></p>
<p>去除一个最大值使得 z 中的元素最大值为 0，这样
exp(0)=1既保证了分母不会为0，同时也保证了分子不会发生上溢</p>
<h1 id="病态问题">病态问题</h1>
<p>参考<a
href="%5B病态问题及条件数%20%7C%20断鸿声里，立尽斜阳%20(flat2010.github.io)%5D(https://flat2010.github.io/2018/06/30/病态问题及条件数/)">这篇博客</a></p>
<p>基于条件数的定义：定义方程组关于A的条件数为：<span
class="math inline">\(k(A)=||A|| · ||A^{-1}||\)</span></p>
<p>所以假定 <span class="math inline">\(\vec b\)</span> 的变化为 <span
class="math inline">\(\Delta \vec b\)</span> ，对应解的变化为 <span
class="math inline">\(\Delta \vec x\)</span></p>
<p>所以有 <span class="math inline">\(A(x+\Delta x)=b+\Delta b\)</span>
由于方程组 <span class="math inline">\(Ax=b\)</span></p>
<p>所以有 <span class="math inline">\(A·\Delta x=\Delta b\)</span>
，由于条件数假定了 A 的非奇异的，因此存在逆矩阵，所以 <span
class="math inline">\(\Delta x=A^{-1}b\)</span></p>
<p>根据范数的三角不等式有 <span class="math inline">\(||\Delta x || = ||
A^{-1} \Delta b ||\le ||A^{-1}|| · ||b||\)</span></p>
<p>同样地，对原方程做同样的处理有 <span class="math inline">\(||A|| ·
||x|| \ge ||Ax|| = ||b||\)</span></p>
<p>于是能够得到 <span class="math inline">\(\frac {||\Delta x ||}{||A||·
||x|} \le \frac{||A^{-1}|| · ||\Delta b|| }{||b ||}\)</span></p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404281529331.png" alt="image-20240428152927261" style="zoom:50%;" /></p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404281530640.png" alt="image-20240428153016606" style="zoom:50%;" /></p>
<blockquote>
<p>所以条件数本质上是输出相对于输出变化的灵敏度系数</p>
</blockquote>
<h3 id="二范数条件数">二范数条件数</h3>
<p>如果取得是二范数 <span class="math inline">\(||·||_2\)</span>
那么条件数为 <span class="math inline">\(k(A) = \frac
{\sigma_{\max}(A)}{\sigma_{\min}(A)}\)</span>​</p>
<p>其中 <span class="math inline">\(\sigma_{\max}\)</span> 、<span
class="math inline">\(\sigma_{\min}\)</span> 分别是矩阵 A
的最大、最小奇异值</p>
<ul>
<li>当 A 为正规阵时， <span
class="math inline">\(k(A)=\frac{|\lambda_{\max}(A)|}{|\lambda_{\min}(A)|}\)</span>
，这里为最大、最小特征值</li>
<li>当 A 为酉矩阵时，<span class="math inline">\(k(A)=1\)</span></li>
<li>当 A 为奇异阵时，由于A逆不存在所以 <span
class="math inline">\(k(A)\to \infty\)</span></li>
</ul>
<h3 id="机器学习和条件数">机器学习和条件数</h3>
<figure>
<img
src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404271622235.png"
alt="image-20240427162132277" />
<figcaption aria-hidden="true">image-20240427162132277</figcaption>
</figure>
<blockquote>
<p>病态的根源是矩阵的列向量相关性过大！</p>
</blockquote>
<h2 id="基于梯度的优化方法">基于梯度的优化方法</h2>
<p>方向导数是函数 <span class="math inline">\(f(x + \alpha u)\)</span>
关于 <span class="math inline">\(\alpha\)</span> 的导数（在 <span
class="math inline">\(\alpha\)</span> 为0时取到），当 <span
class="math inline">\(\alpha=0\)</span> 时有 <span
class="math inline">\(\frac \partial {\partial \alpha}f(x + \alpha
u)=u^T \nabla_x f(x)\)</span></p>
<p>而计算方向导数为了得到使得 f 下降最快的方向 （梯度下降）</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404281918701.png" alt="image-20240428191800654" style="zoom:50%;" /></p>
<p>关于梯度，是看的是函数增长的速度，二阶导数是对曲率的衡量。假设我
们有一个二次函数（虽然很多实践中的函数都不是二次的，但至少在局部可以很好
地用二次近似）。如果这样的函数具有零二阶导数，那就没有曲率。也就是一条完全
平坦的线，仅用梯度就可以预测它的值。</p>
<p>有时我们需要计算输入和输出都为向量的函数的所有偏导数。包含所有这样的
偏导数的矩阵被称为 Jacobian 矩阵。具体来说，如果我们有一个函数：<span
class="math inline">\(f:\mathbb R^m \to \mathbb R^n\)</span> ，f 的
Jacobian 矩阵 <strong>J</strong><span class="math inline">\(\in \mathbb
R^{n\times m}\)</span> 定义为 <span class="math inline">\(J_{i,j}=\frac
\partial {\partial x_j}f(x)_i\)</span></p>
<p>当我们的函数具有多维输入时，二阶导数也有很多。我们可以将这些导数合并
成一个矩阵，称为 <strong>Hessian 矩阵</strong>。Hessian 矩阵 H(f)(x)
定义为</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404281919062.png" alt="image-20240428191907022" style="zoom:50%;" /></p>
<p>微分算子在任何二阶偏导连续的点处可交换，也就是它们的顺序可以互换
=&gt; 因为 Hessian
矩阵是实对称的，我们可以将其分解成一组实特征值和一组特征向量的正交基。在特定方向
d 上的二阶导数可以写成 <span class="math inline">\(d^T Hd\)</span> 。当
d 是 H 的一个特征向量时，这个方向的二阶导
数就是对应的特征值。对于其他的方向
d，方向二阶导数是所有特征值的加权平均， 权重在 0 和 1 之间，且与 d
夹角越小的特征向量的权重越大。最大特征值确定最
大二阶导数，最小特征值确定最小二阶导数。</p>
<blockquote>
<p>当作梯度下降时，我们通过泰勒公式去近似看一次下降能表现得多好（新的点x应该是
<span class="math inline">\(x^{(0)-\epsilon g}\)</span> ,g为梯度）</p>
<p>那么有近似</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404281924928.png" alt="image-20240428192440882" style="zoom:67%;" /></p>
<p>其中有 3
项：函数的原始值、函数斜率导致的预期改善、函数曲率导致的校正</p>
<p>当 最后一项太大时，梯度下降实际上是可能向上移动的。当 g ⊤Hg
为零或负时，近似的泰勒级数表明增加 ϵ 将永远使 f 下降。</p>
<p>当 <span class="math inline">\(g^⊤Hg\)</span> 为正时，通
过计算可得，使近似泰勒级数下降最多的最优步长为</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404281925071.png" alt="image-20240428192555024" style="zoom: 67%;" /></p>
<p>最坏的情况下，g 与 H 最大特征值 <span
class="math inline">\(λ_{\max}\)</span> 对应的特征向量对齐，则最优步长是
<span class="math inline">\(\frac {1} {λ{_\max}}\)</span> 。</p>
</blockquote>
<p>对于鞍点或局部极值点的讨论：</p>
<ul>
<li>当 Hessian
是正定的（所有特征值都是正的），则该临界点是局部极小点。</li>
<li>当 Hessian
是负定的（所有特征值都是负的），这个点就是局部极大点。</li>
<li>如 果 Hessian 的特征值中至少一个是正的且至少一个是负的，那么 x 是 f
某个横截面 的局部极大点，却是另一个横截面的局部极小点。</li>
</ul>
]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>花书</tag>
        <tag>Deep Learning</tag>
        <tag>数值计算</tag>
      </tags>
  </entry>
  <entry>
    <title>花书——线代and概率论</title>
    <url>/2024/04/15/%E8%8A%B1%E4%B9%A6%E2%80%94%E2%80%94%E7%BA%BF%E4%BB%A3and%E6%A6%82%E7%8E%87%E8%AE%BA/</url>
    <content><![CDATA[<blockquote class="blockquote-center">
<p>研读花书，皆为拙记，如有错误还望各位不惜笔墨，不啬赐教。本节主要包括<strong>线性代数</strong>与<strong>概率论</strong>部分内容</p>

</blockquote>
<span id="more"></span>
<p>当然，笔者所记不能是花书所有的内容，只能是笔者自己觉得有提升、有意义的部分，所以很多课堂上已经掌握的内容就没有纳入本文的内容了</p>
<h1 id="引言">引言</h1>
<p>一些人工智能项目旨在将世界所包含的知识用形式化的语言进行硬编码
(hard-code)
，而计算机可以使用逻辑推理规则自动理解这些形式化语言中的声明。这就是人工智能的<strong>知识库</strong>
(knowledge base)</p>
<p>依靠硬编码的知识体系面对的困难表明，AI系统需要具备自己获取知识的能力，即从原始数据中提取模式的能力——机器学习
(machine learning) 的能力</p>
<p>对于很多任务来说，我们很难知道应该提取哪些特征，解决这个问题的途径之一就是使用机器学习来发掘表示本身，而不仅仅把表示映射到输出，这种方法称之为<strong>表示学习</strong>
(representation learning)</p>
<blockquote>
<p>一个典型例子是自编码器 (autoencoder)。自编码器由一个编码器 (encoder)
和一个解码器 (decoder)
函数构成。编码器函数将输入数据转为一种不同的表示，而解码器函数则将这个新的表示转换到原来的形式。<br />
而我们的目标是：数据经过编码器和解码器能够尽可能多地保留信息，同时，新的表示有一些好的特性。。。</p>
</blockquote>
<p>设计特征或设计用于学习特征的算法时，我们的目标通常是分离出能够解释观察数据的
<strong>变差因素</strong> (factors of variation) 。</p>
<blockquote>
<p>这些因素可能是现实世界中观察不到的物体或者不可观测的力，但会影响可观测的量<br />
比如分析语音记录时，变差因素包括说话者的年龄、性别等等。。。</p>
</blockquote>
<p>深度学习 (deep learning)
通过其他较为简单的表示来表示复杂表达，解决了表示学习中的核心问题</p>
<blockquote>
<p>如在图片理解这个任务上，计算机是难以理解以像素集合的图像的<br />
直接处理，让机器学习或评估几乎是不可能的<br />
深度学习将复杂的映射分解为一系列嵌套的简单的映射<br />
输入展示在可见层 (visible
layer)，命名的原因是它包含我们能够观察到的变量<br />
然后经过一系列的隐藏层 (hiden layer)</p>
</blockquote>
<p>评估模型深度的方式主要有两种：</p>
<ul>
<li>评估计算流深度</li>
<li>评估概念关联深度
<ul>
<li>比如一个AI系统观察到一只眼睛在阴影中的脸部图象时，他可能看到一只眼睛。但是当其检测到脸部的存在后，系统可能推断第二只眼睛也是存在的。这种情况下，概念图包括两层关系（关于眼睛的层和关于脸的层），但如果我们细化每个概念的估计需要额外的
n 次计算，也就是说计算的图包含 2n 层</li>
</ul></li>
</ul>
<hr />
<h1 id="线性代数">线性代数</h1>
<p>在这里，矩阵被看作是列向量集合，即 <span
class="math inline">\(A=[\alpha_1,\alpha_2,\alpha_3,\cdots,\alpha_n]\)</span>
，而每个列向量被看作是方向的描述<br />
因此 <span class="math inline">\(Ax=\sum_i x_iA_{:,i}\)</span>
可以被描述为我们需要沿着第<span
class="math inline">\(i\)</span>个向量的方向走<span
class="math inline">\(x_i\)</span>的步长</p>
<p>一组向量的 <strong>生成子空间(span)</strong>
是原始向量线性组合后所能抵达的点的集合<br />
也就是说，方程 <span
class="math inline">\(Ax=b\)</span>是否有解，相当于：确定向量<span
class="math inline">\(b\)</span>是否在<span
class="math inline">\(A\)</span>的列向量集合的生成子空间中，这个特殊的生成子空间也被称为
<span class="math inline">\(A\)</span> 的<strong>列空间(column
space)</strong> 或是<span
class="math inline">\(A\)</span>的<strong>值域(range)</strong> 。</p>
<h2 id="讨论方程-axb-是否有解">讨论方程 <span
class="math inline">\(Ax=b\)</span> 是否有解？</h2>
<blockquote>
<p>前提我们记 <span class="math inline">\(A\)</span> 的形状为 <span
class="math inline">\(m \times n\)</span></p>
</blockquote>
<p>那么一方面，若要求该方程对任意的<span
class="math inline">\(b\)</span>都要有解，由于<span
class="math inline">\(Ax\)</span> 看作是<span
class="math inline">\(A\)</span>的第<span
class="math inline">\(i\)</span>个列向量，所以<span
class="math inline">\(Ax\)</span>自然有<span
class="math inline">\(n\)</span>个，故若<span
class="math inline">\(Ax\)</span>的列空间是整个<span
class="math inline">\(\mathbb{R}^m\)</span>要求<span
class="math inline">\(n\ge m\)</span><br />
（当然，这只是必要条件，这些列向量会存在冗余，这种现象称之为
<strong>线性相关</strong> ）</p>
<p><br></p>
<p>另一方面，如果想要该矩阵可逆，需要使得方程对每一个 <span
class="math inline">\(b\)</span> 至多有一个解。</p>
<blockquote>
<p>这一句可能有些同学一开始看会愣一下，笔者在这里卡了一下，作者的意思是
<span class="math inline">\(Ax=b\)</span>，既然<span
class="math inline">\(A\)</span>是广义上可逆的，那么 <span
class="math inline">\(x=A^{-1}b\)</span> ，也就是说，x是 <span
class="math inline">\(A^{-1}\)</span>
的列空间中的一个向量，所以说，x至多也只能有一个，不可能在<span
class="math inline">\(A\)</span>可逆的情况下一个 <span
class="math inline">\(b\)</span> 向量对应多个 <span
class="math inline">\(x\)</span> 向量</p>
</blockquote>
<p>所以该矩阵需要确保至多有 <span class="math inline">\(m\)</span>
个列，当然，这是个充分条件<br />
综上所述，如果方程有唯一解那么 <span class="math inline">\(A\)</span>
矩阵首先要是方阵，其次他所有的列向量都要是无关的</p>
<h2 id="范数">范数</h2>
<p>在机器学习中，我们通过称为 <strong>范数</strong>
(norm)的函数来衡量向量的大小，形式上 <span
class="math inline">\(L^p\)</span>范数的定义为： <span
class="math display">\[ | | x | | _ { p } = \left( \sum _ { i } | x _ {
i } | ^ { p } \right) ^ { \frac { 1 } { p } }\]</span><br />
范数能够将向量映射为非负值<br />
直观上来看，向量<span
class="math inline">\(x\)</span>的范数衡量了从原点到点<span
class="math inline">\(x\)</span>的距离，更严格地说，范数满足如下性质：</p>
<ul>
<li><span class="math inline">\(f(x)=0 \rightarrow x=\vec
0\)</span></li>
<li><span class="math inline">\(f(x+y) \le f(x) + f(y)\)</span></li>
<li><span class="math inline">\(\forall \alpha \in R , f (\alpha x) =
|{\alpha}|f(x)\)</span></li>
</ul>
<p>举几个例子吧！</p>
<ul>
<li>当 <span class="math inline">\(p = 2\)</span> 时，<span
class="math inline">\(L^2\)</span> 范数称为
<strong>欧几里得范数</strong>(Euclidean norm)：表示从原点出发到向量
<span class="math inline">\(x\)</span>
确定的点的欧几里得距离。通常情况也用 <span
class="math inline">\(L^2\)</span> 范数的平方去代替 <span
class="math inline">\(L^2\)</span>
范数，不过也有利有弊，一方面，平方在原点附近的增长非常缓慢，另一方面，平方的导数只取决于对应的元素</li>
<li>当 <span class="math inline">\(p = 1\)</span> 时， <span
class="math inline">\(L^1\)</span>
范数却能够给我们区分零元素和非零元素， <span
class="math inline">\(L^1\)</span>
范数的计算也非常简单，即各位的绝对值和</li>
<li>当 <span class="math inline">\(p = 0\)</span> 时，这种 <span
class="math inline">\(L^0\)</span>
范数用来统计向量中非零元素的个数，有时我们会用他来衡量一个向量的大小，但这个概念对于前面数学上的严格定义是不对的，首先第三条就不满足了。。。</li>
<li>当 <span class="math inline">\(p = +\infty\)</span>
时，也被称为<strong>最大范数</strong>(max
norm)，这个范数表示向量中具有最大幅值的元素的绝对值：<span
class="math inline">\(||x||_\infty=\max_i |x_i|\)</span></li>
<li>当然，在机器学习中，我们有时也希望有类似的定义能够去衡量矩阵的大小，这要引入
<strong>Frobenius范数</strong>(Frobenius norm)： <span
class="math inline">\(||A||_F=\sqrt{\sum_{i,j}A^2_{i,j}}\)</span>
（类似于向量的 L2 范数？）</li>
</ul>
<h2 id="特征分解">特征分解</h2>
<blockquote>
<p>许多数学对象可以通过将它们分解成多个组成部分或者找到它们的一些属性而更好地理解，这些属性是通用的，而不是由我们选择表示它们的方式产生的。<br />
例如：$12=2×3×3 $，从中我们可以获得一些信息，比如12不能被5整除</p>
</blockquote>
<p>通过矩阵的<strong>特征分解</strong>(eigen
decomposition)我们同样能够获得一些信息，方阵 A 的 特征向量（eigen
vector）是指与 A 相乘后相当于对该向量进行缩放的非零向量 v：<span
class="math inline">\(Av=\lambda v\)</span><br />
其中 <span class="math inline">\(\lambda\)</span>
称为这个特征向量对应的特征值(eigen value)。（类似地，我们也可以定义
左特征向量（left eigen vector）<span class="math inline">\(v^⊤A =
λv^⊤\)</span>，但是通常我们更关注 右特征向量（right eigen
vector））。显然，对特征向量缩放后的向量依然是矩阵的特征向量。<br />
假设矩阵 A 有 n 个线性无关的特征向量 <span
class="math inline">\(\{v^{(1)},\cdots,v^{(n)}\}\)</span> 对应着特征值
<span
class="math inline">\(\{\lambda^{(1)},\cdots,\lambda^{(n)}\}\)</span> ,
因此 A 的特征分解可以记作： <span class="math inline">\(A=V\rm
diag(\lambda)V^{-1}\)</span><br />
不过值得注意的是，并不是所有实矩阵都总有实特征分解，有些特征分解存在但是涉及到复数，不过值得注意的是，所有的<strong><em>实对称阵</em></strong>都可以分解成实特征向量和实特征值：<span
class="math inline">\(A=Q \Lambda Q^T\)</span>，其中 <span
class="math inline">\(Q\)</span> 是 <span
class="math inline">\(A\)</span> 的特征向量组成的正交矩阵，<span
class="math inline">\(\Lambda\)</span> 是对角矩阵。<br />
<img
src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404251812391.png"
alt="image-20240425181235305" /></p>
<h2 id="奇异值分解">奇异值分解</h2>
<p>对于非方阵矩阵，我们同样希望能够进行分解，换句话说我们希望将特征分解的范围拓展<br />
这种分解方法被称为 <strong>奇异值分解</strong>（singular value
decomposition, SVD），将矩阵分解为 奇异向量（singular vector）和
<strong>奇异值</strong>（singular value）<br />
同样地，奇异值分解为：<span class="math inline">\(A=UDV^T\)</span><br />
假设 A 是一个 <span class="math inline">\(m\times
n\)</span>的矩阵,那么U是一个 <span class="math inline">\(m\times
m\)</span>的矩阵,D是一个<span class="math inline">\(m\times
n\)</span>的矩阵,V是一个 <span class="math inline">\(n \times n\)</span>
的矩阵<br />
矩阵 U 和 V 都定义为 <strong>正交矩阵</strong>，而矩阵 D
定义为<strong>对角矩阵</strong>。注意，矩阵 D 不一定是方阵。<br />
对角矩阵 D 对角线上的元素被称为矩阵 A 的
<strong>奇异值</strong>（singular value）。矩阵U 的列向量被称为
<strong>左奇异向量</strong>（left singular vector），矩阵 V 的列向量被称
<strong>右奇异向量</strong>（right singular vector）。<br />
事实上，我们可以用与 A 相关的特征分解去解释 A 的奇异值分解。A 的
左奇异向量（left singular vector）是 <span
class="math inline">\(AA^⊤\)</span> 的特征向量。A 的 右奇异向量（right
singular vector）是 <span class="math inline">\(A^⊤A\)</span>
的特征向量。A 的非零奇异值是 <span class="math inline">\(A^⊤A\)</span>
特征值的平方根，同时也是<span class="math inline">\(AA^⊤\)</span>
特征值的平方根。<br />
奇异值分解的推导如下：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261123476.jpg" alt="53ad37ea04a14b4601663211b5ac23d" style="zoom: 50%;" /></p>
<blockquote>
<p><a
href="https://www.bilibili.com/video/BV1544y1v7Am/?spm_id_from=333.337.search-card.all.click">参考视频</a></p>
</blockquote>
<h2 id="mp伪逆">MP伪逆</h2>
<p>对于非方阵而言，其逆运算没有定义，因此我们也需要对逆的概念进行拓展<br />
如果矩阵 A 的行数大于列数，那么上述方程可能没有解。如果矩阵 A
的行数小于列数，那么上述矩阵可能有多个解<br />
Moore-Penrose 伪逆（Moore-Penrose
pseudoinverse）使我们在这类问题上取得了一定的进展。矩阵 A
的伪逆定义为：$ A ^ { + } = _ { } ( A ^ { T } A + I ) ^ { - 1 } A ^ { T
}$</p>
<p>而计算伪逆通常使用奇异值分解：$ A ^ { + } = V D ^ { + } U ^ { T }
$<br />
其中，矩阵 U，D 和 V 是矩阵 A奇异值分解后得到的矩阵。对角矩阵 D
的伪逆<span class="math inline">\(D^+\)</span>
是其非零元素<strong>取倒数之后再转置</strong>得到的。<br />
MP伪逆在方程解的问题中也有很多应用，比如：</p>
<ul>
<li>当 <span class="math inline">\(n &gt; m\)</span> 时，<span
class="math inline">\(x = A^+ y\)</span>是所有方程可行解中<span
class="math inline">\(L_2\)</span>范数最小的那个</li>
<li>当 <span class="math inline">\(n &gt; m\)</span>​
时，MP伪逆得到的解使得 <span class="math inline">\(Ax\)</span>​ 与 <span
class="math inline">\(y\)</span>​​ 的欧几里得距离最小</li>
</ul>
<h2 id="迹运算">迹运算</h2>
<p>迹运算主要集中于以下几点</p>
<ul>
<li><span class="math inline">\(Tr(A) = \sum_i A_{i,i}\)</span></li>
<li><span class="math inline">\(Tr(A) = Tr(A^T)\)</span></li>
<li><span class="math inline">\(||A||_F=\sqrt{Tr(AA^T)}\)</span></li>
<li>$ Tr ( {_ { i = 1 } ^ { n }} {F ^ { ( i ) }} ) = Tr ( F ^ { ( n ) }
{_ { i = 1 } ^ { n - 1 }} {F ^ { ( i ) }} ) $​
(多个矩阵相乘得到的方阵的迹，和将这些矩阵中的最后一个挪到最前面之后相乘的迹是相同的)</li>
</ul>
<h2 id="行列式">行列式</h2>
<p>行列式，记作 det(A)，是一个将方阵 A
映射到实数的函数。行列式等于矩阵特征值的乘积。行列式的绝对值可以用来衡量矩阵参与矩阵乘法后空间扩大或者缩小了多少。如果行列式是
0，那么空间至少沿着某一维完全收缩了，使其失去了所有的体积。如果行列式是
1，那么这个转换保持空间体积不变。</p>
<h2 id="主成分分析">主成分分析</h2>
<p>主成分分析（principal components analysis, PCA）</p>
<hr />
<p>首先，假设我们有 <strong>m 个 n 维的样本 <span
class="math inline">\(\{x_1,x_2, \cdots,x_m\},x_i\in
R^n\)</span></strong> ，我们希望使用某种压缩，对于每个 <span
class="math inline">\(x_i\)</span> 找到对应的 <strong><span
class="math inline">\(c_i \in R^l\)</span> ，一般的 $l &lt; n $</strong>
，进行压缩</p>
<ul>
<li>对于编码器 <span class="math inline">\(f(x) = c\)</span></li>
<li>对于解码器 <span class="math inline">\(x \approx g
(c)=g(f(x))\)</span></li>
</ul>
<p>为了简化解码函数的选择，我们可以通过矩阵乘法将其映射回 n 维空间，即
<span class="math inline">\(g (c) = Dc\)</span></p>
<p>注意到，当 c
等比例扩大缩小时，D同样等比例缩小扩大，可以得到无数个结果，因此我们限制
D 中的所有列向量都有单位范数</p>
<p>同样，为了让编码问题更简单，PCA限制 D
的列向量彼此正交（D不是严格意义上的正交阵）</p>
<p>我们如何去找到这个 c
，使得他能够被精确解码？这里给出的方法是最小化原始向量 <span
class="math inline">\(x\)</span> 与重构向量 <span
class="math inline">\(g(c^*)\)</span> 的距离，即 <span
class="math inline">\(c^*={\rm arg\ min}_c ||x-g(c)||_2\)</span>
，由于二范数非负性，所以我们可以通过平方进行优化</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261520572.png" alt="image-20240426152011469" style="zoom:33%;" /></p>
<p>由于第一项并不依赖于 c ，所以可以再度简化为 <span
class="math inline">\(c^*={\rm arg\ min}_c -2 x^T g (c)+g (c)^T g
(c)\)</span></p>
<p>带入 <span class="math inline">\(g (c)\)</span> 的定于，以及 <span
class="math inline">\(D\)</span>
矩阵的列向量互相正交的一些约定，我们有</p>
<p><span class="math display">\[c^* = {\rm arg\ min}_c - 2 x ^ { T } D c
+ c ^ { T } c\]</span></p>
<p>通过向量微积分，能够推导得到结论：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261229634.png" alt="image-20240426122900565" style="zoom:33%;" /></p>
<p>所以推导得到编码函数也就能够写成 <span
class="math inline">\(f(x)=D^Tx\)</span></p>
<p>那么，另一方面该如何选取投影矩阵 D ？</p>
<p>当然这个 D
是作用在全体样本上，与刚刚的思路类似，我们需要使得误差矩阵的
<strong>Frobenius 范数</strong>最小，也就是 <span
class="math inline">\(D^*={\rm arg\ min}_D
\sqrt{\sum_{i,j}(x_j^{(i)}-r(x^{(i)})_j)^2}{\rm \ subject\ to\
}D^TD=I_l\)</span> 其中 <span
class="math inline">\(r(x)=g(f(x))=DD^Tx\)</span></p>
<p>首先考虑一维的情况，问题简化为：</p>
<p><span class="math display">\[d^*={\rm arg\ min}_d
\sqrt{\sum_{i}(x^{(i)}-d{d^T}{x^{(i)}})^2}{\rm \ subject\ to\
}||d||_2=1\]</span></p>
<p>由于 <span class="math inline">\(d^T x\)</span>
是标量，可以重排位置，参考花书</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261243605.png" alt="image-20240426124335517" style="zoom: 50%;" /></p>
<p>这里求和号实际上不方便理解，因此我们写成矩阵的形式，重新表述为<span
class="math display">\[d^*={\rm arg\ min}_d ||X-Xd{d^T}||_F^2\ {\rm
subject\ to\ }d^Td=1\]</span></p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261248438.png" alt="image-20240426124828340" style="zoom:67%;" /></p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261253697.png" alt="image-20240426125338607" style="zoom:50%;" /></p>
<p>这里将 <span class="math inline">\(X^TX\)</span> 处理为对称阵，那么
<span class="math inline">\(y^TX^TXy\)</span>
就是一个二次型，那么显然他的最大值应该是最大特征值，对应y向量为对应特征值的特征向量。。。</p>
<h1 id="概率论">概率论</h1>
<p>不确定信息的来源：</p>
<ul>
<li>被建模系统内在的随机性。这个好理解，比如打扑克，洗牌当然存在一定的随机性</li>
<li>不完全观测。这个也好理解，我们没有办法总能够观察到所有驱动系统行为的变量。</li>
<li>不完全建模。当我们使用一些必须舍弃某些观测信息的模型时，舍弃的信息会导致模型的预测出现不确定性。</li>
</ul>
<p>在引入贝叶斯概率后，概率呈现出两种意义：</p>
<ul>
<li>直接与事件发生的概率相联系——<strong>频率派概率(frequentist
probability)</strong></li>
<li>涉及到确定性水平——<strong>贝叶斯概率(Bayesian
probability)</strong></li>
</ul>
<h2 id="概率分布">概率分布</h2>
<h3 id="离散型随机变量">离散型随机变量</h3>
<p>离散型变量的概率分布可以用 <strong>概率质量函数(probability mass
function, PMF)</strong> 来描述，通常用大写字母 P
来表示PMF。PMF可以同时作用于多个随机变量，这多个变量的概率分布被称为<strong>联合概率分布(joint
probability
distribution)</strong>，如果一个函数是随机变量x的PMF，必须要满足一些条件：</p>
<ul>
<li>P定义域为所有x的状态集合</li>
<li><span class="math inline">\(\forall x\in {\rm x},0\le P(x)\le
1\)</span></li>
<li><span class="math inline">\(\sum_{x\in {\rm x}}P(x)=1\)</span>​
，这条性质称为归一化的(normalized)</li>
</ul>
<h3 id="连续性随机变量">连续性随机变量</h3>
<p>同理，这里的PMF被描述为概率密度函数<strong>(probability density
function，PDF)</strong> ，同样的，他需要满足几个条件：</p>
<ul>
<li>p定义域是所有x可能的状态的集合</li>
<li><span class="math inline">\(\forall x\in {\rm x},p(x)\ge 0\)</span>
（！这里不要求 <span class="math inline">\(p(x)\le 1\)</span>
因为一个点处的密度哪怕是非常大，也不一定能够影响总体的概率</li>
<li><span class="math inline">\(\int p(x) \mathrm dx=1\)</span></li>
</ul>
<p>概率密度函数 <span class="math inline">\(p(x)\)</span>
并没有直接对特定的状态给出概率，相对的，它给出了落在面积为 <span
class="math inline">\(δx\)</span> 的无限小的区域内的概率为 <span
class="math inline">\(p(x)δx\)</span>。</p>
<h2 id="边缘概率">边缘概率</h2>
<p>若我们知道一组变量的联合概率分布，但只需要了解其中一个子集的分布，那么我们可以如下计算：</p>
<ul>
<li>离散型</li>
</ul>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261538617.png" alt="image-20240426153859533" style="zoom: 50%;" /></p>
<ul>
<li>连续型</li>
</ul>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261539368.png" alt="image-20240426153922287" style="zoom:50%;" /></p>
<p>​</p>
<h2 id="条件概率">条件概率</h2>
<p>条件概率可以通过公式 <span class="math inline">\(P(\mathrm
y=y|\mathrm x=x)=\frac {P(\mathrm y=y,\mathrm x=x)}{P(\mathrm
x=x)}\)</span></p>
<blockquote>
<p>这里需要注意的是，不要把条件概率和计算当采用某个动作后会发生什么相混淆。假定某个人说德语，那么他是德国人的条件概率是非常高的，但是如果随机选择的一个人会说德语，他的国籍不会因此而改变。计算一个行动的后果被称为
<strong>干预查询（intervention query）</strong>。干预查询属于
<strong>因果模型（causal modeling）</strong>的范畴</p>
</blockquote>
<p>参考了网络上的一些解释，笔者的浅显理解是，调剂概率强调状态而干预查询强调改变</p>
<p>例如<span class="math inline">\(P(销售量|汉堡的价格为20元)\)</span>
与 <span class="math inline">\(P(销售量|降价至20元)\)</span>
，前者是条件概率而后者则是干预查询</p>
<h2 id="独立与条件独立">独立与条件独立</h2>
<p>对于两个随机变量x和y，广义的独立是他们的某种概率可以拆分成互不相关的两个因子的乘积形式，即认为他们是独立的</p>
<ul>
<li>独立：<span class="math inline">\(\forall x\in \mathrm x,y\in
\mathrm y,p(\mathrm x=x,\mathrm y=y)=p(\mathrm x=x)p(\mathrm
y=y)\)</span></li>
<li>条件独立：<span class="math inline">\(\forall x\in \mathrm x,y\in
\mathrm x,z\in \mathrm z,p(\mathrm x=x,\mathrm y=y|\mathrm
z=z)=p(\mathrm x=x|\mathrm z=z)p(\mathrm y=y|\mathrm z=z)\)</span></li>
</ul>
<p>可以使用一种较为简单的记号去描述他们的独立性</p>
<ul>
<li>x和y相互独立：<span class="math inline">\(x⊥y\)</span></li>
<li>x和y在给定条件为z时条件独立：<span
class="math inline">\(x⊥y|z\)</span></li>
</ul>
<h2 id="常用概率分布">常用概率分布</h2>
<h3 id="bernoulli-分布">Bernoulli 分布</h3>
<p>伯努利分布是单个二值随机变量的分布。他由单个参数 <span
class="math inline">\(\phi\in [0,1]\)</span> 控制，他具有一些性质：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261625113.png" alt="image-20240426162520022" style="zoom:50%;" /></p>
<h3 id="multinoulli-分布">Multinoulli 分布</h3>
<p><strong>Multinoulli 分布（multinoulli distribution） </strong> 或者
<strong>范畴分布（categorical distribution）</strong> 是指在具有 k
个不同状态的单个离散型随机变量上的分布，其中 k 是一个有限值</p>
<p>Multinoulli分布由向量 <span class="math inline">\(p\in
[0,1]^{k-1}\)</span> 参数化，其中每一个分量 <span
class="math inline">\(p_i\)</span> 表示第 i 个状态的概率，第 k
个状态可以通过 <span class="math inline">\(1-1^Tp\)</span>
给出，因此需要加以限制 <span class="math inline">\(1^Tp\le
1\)</span></p>
<h3 id="高斯分布">高斯分布</h3>
<p>实数上最常用的分布就是<strong>正态分布（normal
distribution），也称为高斯分布 （Gaussian distribution）</strong>：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261635773.png" alt="image-20240426163530679" style="zoom:50%;" /></p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261637708.png" style="zoom: 50%;" /></p>
<p>正态分布由两个参数控制，<span class="math inline">\(\mu \in
R\)</span> 和 <span class="math inline">\(\sigma\in (0,\infty)\)</span>
。<span class="math inline">\(\mu\)</span>
给出了参数的均值，也是分布的均值，标准差用 <span
class="math inline">\(\sigma\)</span> 控制，方差为 <span
class="math inline">\(\sigma^2\)</span></p>
<p>通常情况下，为了控制正态分布，不会选择直接控制 <span
class="math inline">\(\sigma\)</span> 而是控制 <span
class="math inline">\(\beta = \sigma^{-1}\)</span></p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261641779.png" alt="image-20240426164110685" style="zoom: 50%;" /></p>
<p>一般地，当缺乏对某个实数上分布的先验知识而不知道怎么选择分布时，正态分布是默认比较好的选择，有两个原因：</p>
<ul>
<li>一方面，根据<strong>中心极限定理</strong>，很多独立随机变量的和近似服从正态分布。故实际上一些复杂的系统可以被建模成正态分布的噪声</li>
<li>另一方面，在具有相同方差的所有可能的概率分布中，正态分布在实数上具有<strong>最大的不确定性</strong>。</li>
</ul>
<p>同样的，将正态分布推广到高维形式，其参数推广为矩阵化：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261647279.png" alt="image-20240426164738186" style="zoom:50%;" /></p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261647004.png" alt="image-20240426164752911" style="zoom:50%;" /></p>
<p>同样我们通过精度阵对概率密度函数进行控制</p>
<h3 id="指数分布与laplace分布">指数分布与Laplace分布</h3>
<p>在深度学习中，我们经常会需要一个在 x = 0 点处取得边界点 (sharp point)
的分布。为了实现这一目的，我们可以使用 <strong>指数分布（exponential
distribution）</strong>：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261649599.png" alt="image-20240426164952506" style="zoom: 50%;" /></p>
<p>指数分布使用<strong>指示函数(indicator function) <span
class="math inline">\(1_{x\ge 0}\)</span></strong>
来使得x为负时的值为0</p>
<p>一个与指数分布类似的函数是拉普拉斯分布，它能够控制在任意一点<span
class="math inline">\(\mu\)</span> 处设置概率质量的峰值：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261651323.png" alt="image-20240426165159227" style="zoom:50%;" /></p>
<h3 id="dirac分布和经验分布">Dirac分布和经验分布</h3>
<p>既然拉普拉斯分布可以控制峰值，那么有没有一种分布可以控制将所有的质量集中在一个点处呢？答案是有的，可以通过
<strong>Dirac delta函数（Dirac delta
function，也称单位脉冲函数）</strong> <span
class="math inline">\(\delta(x)\)</span> 定义概率密度函数来实现：<span
class="math inline">\(p(x)=\delta(x-\mu)\)</span></p>
<p>Dirac
delta函数被定义为在除了0以外的所有点的值都为0，但是积分为1，也就是说，他在<span
class="math inline">\(\mu\)</span>​ 处无限窄也无限高</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261710997.png" alt="image-20240426171020870" style="zoom:50%;" /></p>
<p><strong>说明</strong>:</p>
<ul>
<li>严格来说狄拉克δ函数不能算是一个函数，而是一种<strong>数学对象</strong>,
因为满足以上条件的函数是不存在的, 但是我们可以用分布的概念来解释,
因此称为<strong>狄拉克分布</strong>或者<strong>δ分布</strong></li>
<li>它是一种极简单的<strong>广义函数</strong>. 广义函数是一种数学对象,
依据积分性质而定义. 我们可以把狄拉克δ函数想成一系列函数的极限点,
这一系列函数把除0以外的所有点的概率密度越变越小</li>
</ul>
<p>Dirac狄拉克分布经常作为<strong>经验分布（empirical
distribution）</strong>的一个组成部分出现：</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261706821.png" alt="image-20240426170656725" style="zoom:50%;" /></p>
<p>经验分布将概率密度<span class="math inline">\(\frac 1m\)</span>​
赋给m个点，这些点是给定的数据集或者采样的集合。只有在定义连续型随机变量的经验分布时，Dirac
delta
函数才是必要的。对于离散型随机变量，情况更加简单：经验分布可以被定义成一个
Multinoulli
分布，对于每一个可能的输入，其概率可以简单地设为在训练集上那个输入值的
<strong>经验频率（empirical frequency）</strong>。</p>
<h3 id="分布混合">分布混合</h3>
<p>通过组合一些简单的概率分布来定义新的概率分布也是很常见的。一种通用的组合方法是构造
<strong>混合分布（mixture distribution）</strong>。混合分布由一些组件
(component) 分布构成。</p>
<p>简单来说就是根据范畴分布将一个概率密度集合进行抽样并组合</p>
<p>可以看 <a
href="%5B混合分布(mixture%20distribution)-CSDN博客%5D(https://blog.csdn.net/tanghonghanhaoli/article/details/90543917)">这篇博客</a></p>
<h2 id="常用函数的有用性质">常用函数的有用性质</h2>
<p>logistic sigmoid函数作为深度学习中的经典函数：<span
class="math inline">\(\sigma(x)=\frac 1{1+\exp(-x)}\)</span></p>
<p>logistic sigmoid 函数通常用来产生 Bernoulli 分布中的参数
ϕ，因为它的范围是(0, 1)，处在 ϕ 的有效取值范围内。</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261724580.png" alt="image-20240426172450473" style="zoom:50%;" /></p>
<p>sigmoid 函数 在变量取绝对值非常大的正值或负值时会出现
<strong>饱和（saturate）</strong>现象，意味着函数会
变得很平，并且对输入的微小改变会变得不敏感。</p>
<p>另一个常见函数是 <strong>softplus函数</strong>：<span
class="math inline">\(\zeta(x)=\log(1+\exp(x))\)</span> ,softplus
函数可以用来产生正态分布的 β 和 σ 参数，因为它的范围是 <span
class="math inline">\((0,\infty)\)</span></p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261727966.png" alt="image-20240426172710851" style="zoom:50%;" /></p>
<blockquote>
<p>一些有用的性质。。。</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404261727209.png" alt="image-20240426172733099" style="zoom:67%;" /></p>
</blockquote>
<p>函数 <span class="math inline">\(\sigma^{-1}(x)\)</span>
在统计学中被称为 <strong>分对数（logit）</strong></p>
<h2 id="贝叶斯规则">贝叶斯规则</h2>
<p>通过贝叶斯规则，我们能够在已知 <span class="math inline">\(P(\mathrm
y|\mathrm x)\)</span> 时计算 <span class="math inline">\(P(\mathrm x |
\mathrm y)\)</span></p>
<p><span class="math inline">\(P(\mathrm x | \mathrm y)=\frac{P(\mathrm
x) P(\mathrm y | \mathrm x)}{P(\mathrm y)}\)</span></p>
<p>通常情况下，通过 [全概率公式](<a
href="https://baike.baidu.com/item/全概率公式/9980676#:~:text=若事件A1，A2，…构成一个%20完备事件组%20且都有正概率，则对任意一个事件B，有如下公式成立：%20P%20(B)%3DP%20(BA1)%2BP%20(BA2)%2B...%2BP%20(BAn)%3DP,(B%7CA2)P%20(A2)%20%2B...%20%2B%20P%20(B%7CAn)P%20(An).%20此公式即为全概率公式。">全概率公式_百度百科
(baidu.com)</a> 计算 <span class="math inline">\(P(y)\)</span>
就不需要实现知道 y 的信息了</p>
<h2
id="关于连续性随机变量的一些技术问题">关于连续性随机变量的一些技术问题</h2>
<p>涉及到处理那种相互之间有确定性函数关系
的连续型变量。假设我们有两个随机变量 x 和 y 满足 y = g(x)，其中 g
是可逆的、 连续可微的函数。</p>
<blockquote>
<p>可能有人会想 <span class="math inline">\(p_y(y) =
p_x(g^{−1}(y))\)</span>。但实际上这并不对。</p>
</blockquote>
<p>假设我们有两个标量值随机变量 x 和 y，并且满足 y = x/2 以及 x ∼ U(0,
1)。如果我们使用 <span class="math inline">\(p_y(y) =
p_x(2y)\)</span>，那么 <span class="math inline">\(p_y\)</span> 除了区间
[0, 1/2 ] 以外都为 0，并且在这个区间上的值为 1。这意味着<span
class="math inline">\(\int p_y(y)dy=\frac12\)</span>​</p>
<p>而这违背了概率密度的定义 (积分为
1)。这个常见错误之所以错是因为它没有考虑 到引入函数 g
后造成的空间变形。</p>
<p>我们需要让他在无穷小区域内的概率相同，也就是 <span
class="math inline">\(p(x)\delta x\)</span>相同</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404271353082.png" alt="image-20240427135350894" style="zoom:50%;" /></p>
<h2 id="信息论">信息论</h2>
<p>在机器学习中，我们也可以把信息论应用于连续型变量，
此时某些消息长度的解释不再适用。</p>
<p>信息论的基本想法是一个不太可能的事件居然发生了，要比一个非常可能的事
件发生，能提供更多的信息。</p>
<p>我们想要通过这种基本想法来量化信息。特别地，</p>
<ul>
<li>非常可能发生的事件信息量要比较少，并且极端情况下，确保能够发生的事件
应该没有信息量。</li>
<li>较不可能发生的事件具有更高的信息量。</li>
<li>独立事件应具有增量的信息。例如，投掷的硬币两次正面朝上传递的信息量，
应该是投掷一次硬币正面朝上的信息量的两倍。</li>
</ul>
<p>为了满足上述三个性质，我们定义一个事件 x = x 的
<strong>自信息（self-information）</strong> 为 <span
class="math display">\[ I(x) = -\log P(x)\]</span></p>
<p>其中 <span class="math inline">\(\log\)</span> 就是以自然对数 e
为底的 ln 函数</p>
<p>我们定义的 I(x) 单 位是 奈特（nats）。一奈特是以 1/e
的概率观测到一个事件时获得的信息量。</p>
<p>亦有教材定义使用底数为 2 的对数，单位是
<strong>比特（bit）</strong>或者
香农（shannons）；通过比特度量的信息只是通过奈特度量信息的常数倍。</p>
<p>我们可以用 <strong>香农熵（Shannon entropy）</strong>来对整个概
率分布中的不确定性总量进行量化：</p>
<p><span class="math inline">\(H(x)=\mathbb E_{x\sim P}[I(x)]=-\mathbb
E_{x\sim P}[\log P(x)]\)</span> ，也记作 H(P)。</p>
<p>换言之，一个分布的香农熵是指
==遵循这个分布的事件所产生的期望信息总量== 。</p>
<p>当 x 是连续的，香农熵被称为 <strong>微分熵（differential
entropy）</strong></p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404271413992.png" alt="image-20240427141352865" style="zoom: 67%;" /></p>
<blockquote>
<p><strong>二值随机变量</strong>的香农熵。该图说明了更接近确定性的分布是如何具有较低的香农熵，而更
接近均匀分布的分布是如何具有较高的香农熵。水平轴是
p，表示二值随机变量等于 1 的概率。熵由 <span class="math inline">\((p −
1)\log(1 − p) − p \log p\)</span> 给出。当 p 接近 0
时，分布几乎是确定的，因为随机变量几乎总是 0。当 p 接近 1
时，分布也几乎是确定的，因为随机变量几乎总是 1。当 p = 0.5
时，熵是最大的， 因为分布在两个结果（0 和 1）上是均匀的。</p>
<p>推导：</p>
<p>二值分布记其随机变量为 x，那么 <span class="math inline">\(p(\mathrm
x=x)={p^x} (1-p)^{1-x}\)</span></p>
<p>所以 <span class="math inline">\(H(x)=E(-\log ({p^x}
{(1-p)^{1-x}}))=E(-x\log p+(x-1)\log (1-p))\)</span></p>
<p>由于 <span class="math inline">\(E(x)=p\)</span> ，于是有 <span
class="math inline">\(H(x)=(p-1)\log (1-p)-p\log p\)</span></p>
</blockquote>
<p>对于同一个随机变量 x 有两个单独的概率分布 <span
class="math inline">\(P(x)\)</span> 和 <span
class="math inline">\(Q(x)\)</span>​ ，使用 <strong>KL
散度（Kullback-Leibler (KL) divergence）</strong>
来衡量这两个分布的差异：</p>
<p><span class="math display">\[D_{KL}(P\ ||\ Q)=\mathbb E_{x\sim
P}[\log \frac{P(x)}{Q(x)}]=\mathbb E_{x\sim P}[\log P(x)-\log
Q(x)]\]</span></p>
<p>KL散度衡量的是，当我们使用一种编码，这种编码能够使得概率分布Q产生的消息程度最短，在使用这种编码发送一种由概率分布P产生的消息时，所产生的额外信息</p>
<p>KL 散度有很多有用的性质，最重要的是它是非负的。KL 散度为 0 当且仅当 P
和 Q 在离散型变量的情况下是相同的分布，或者在连续型变量的情况下是 ‘‘几乎
处处’’ 相同的。</p>
<p>==因为 KL
散度是非负的并且衡量的是两个分布之间的差异，它经常被用作分布之间的某种距离。==
然而，它并不是真的距离因为它不是对称的：对于某 些 P 和 Q，<span
class="math inline">\(D_{KL}(P||Q)\neq D_{KL}(Q||P)\)</span>
。这种非对称性意味着选择 <span
class="math inline">\(D_{KL}(P||Q)\)</span> 还是<span
class="math inline">\(D_{KL}(Q||P)\)</span>影响很大。</p>
<p><img src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404271443153.png" alt="image-20240427144308978" style="zoom:67%;" /></p>
<p>!!!一个和 KL 散度密切联系的量是
<strong>交叉熵（cross-entropy）</strong><span class="math inline">\(H(P,
Q) = H(P) + D_{KL}(P||Q)\)</span>，它和 KL
散度很像但是缺少左边一项：</p>
<p><span class="math display">\[H(P,Q)=-\mathbb E_{x\sim P}\log
Q(x)\]</span></p>
<p>针对 Q 最小化交叉熵等价于最小化 KL 散度，因为 Q
并不参与被省略的那一项。</p>
<p>在信息论的计算过程中，经常会遇到 <span class="math inline">\(0\log
0\)</span> 的表达式，按照惯例，将它处理成 <span
class="math inline">\(\lim_{x\to 0}x\log x=0\)</span></p>
]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>花书</tag>
        <tag>Deep Learning</tag>
        <tag>线性代数</tag>
        <tag>概率论</tag>
        <tag>信息论</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo中的markdown语法技巧</title>
    <url>/2024/04/10/hexo%E4%B8%AD%E7%9A%84markdown%E8%AF%AD%E6%B3%95%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<p>参考这篇<a
href="https://www.imczw.com/post/tech/hexo-next-tags-markdown.html">博客</a>，效果确实是很震惊</p>
<span id="more"></span>
<h1 id="居中引用">居中引用</h1>
<blockquote class="blockquote-center">
<p>hello world</p>

</blockquote>
<h1 id="彩色-tag">彩色 tag</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% label [class] @ 标签内容 %&#125;</span><br><span class="line">class：</span><br><span class="line"> - default: 浅灰色,可留空</span><br><span class="line"> - primary: 浅紫色</span><br><span class="line"> - success: 浅绿色</span><br><span class="line"> - info: 浅蓝色</span><br><span class="line"> - warning: 浅黄色</span><br><span class="line"> - danger: 浅红色</span><br></pre></td></tr></table></figure>
<mark class="label [warning]"> test</mark>
<p>注意，由于之前安装的darkmode插件导致了前端css被覆盖，所以实际显示的颜色可能有不同</p>
<h1 id="彩色-note">彩色 note</h1>
<p>我个人很喜欢这个东西 ^ ^</p>
<p>(为了避免编译错误，所以放在不同的行了。。。) <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% note [class]%&#125; </span><br><span class="line">内容</span><br><span class="line">&#123;% endnote %&#125;</span><br><span class="line"></span><br><span class="line">class: </span><br><span class="line"> - default: 灰色</span><br><span class="line"> - primary: 紫色</span><br><span class="line"> - success: 绿色</span><br><span class="line"> - info: 蓝色</span><br><span class="line"> - warning: 黄色</span><br><span class="line"> - danger: 红色</span><br></pre></td></tr></table></figure></p>
<details class="note "><summary><p>[info]</p>
</summary>
<p>hello world</p>

</details>
<h1 id="切换-tabs">切换 tabs</h1>
<p>这个也不错，感觉之后不论是放代码还是放对比的东西，比上下文叠放好用多了。。。<br />
<div class="tabs" id="[class]"><ul class="nav-tabs"><li class="tab active"><a href="#[class]-1">Tab1</a></li><li class="tab"><a href="#[class]-2">Tab2</a></li><li class="tab"><a href="#[class]-3">3号Tab</a></li></ul><div class="tab-content"><div class="tab-pane active" id="[class]-1"><p>这里是1号Tab内容</p></div><div class="tab-pane" id="[class]-2"><p>这里是2号Tab内容</p></div><div class="tab-pane" id="[class]-3"><p>这里是3号Tab内容，上面的tab也可以改 ^ ^</p></div></div></div></p>
<h1 id="按钮-btn">按钮 Btn</h1>
<p>使用自带 FontAwesome 图标，在 <a
href="https://fontawesome.com/v4/icons/">FontAwesome</a>
上找到相应的图标名<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% btn [地址] , [内容] , [图标 规格] %&#125;</span><br><span class="line"></span><br><span class="line">[地址]：当使用外链绝对引用时，无按钮，样式类似Markdown链接跳转</span><br><span class="line">[图标 规格]: 使用无`fa-`开头的FontAwesome图标，可以用以下规格定义图标大小</span><br><span class="line">fa-fw | fa-lg | fa-2x | fa-3x | fa-4x | fa-5x</span><br><span class="line"></span><br></pre></td></tr></table></figure> 但是不知道为什么显示不出来 hhh</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% btn [https://www.baidu.com/] [百度] [fa-home-2x]&#125;  </span><br><span class="line"></span><br><span class="line">&#123;% btn [https://www.baidu.com/] [百度] [fa-home]&#125;  </span><br></pre></td></tr></table></figure>
<p>哎哎，显示不出来我就给他用多行代码的形式注释掉了。。。</p>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>nexT美化</title>
    <url>/2024/04/09/nextT%E7%BE%8E%E5%8C%96/</url>
    <content><![CDATA[<p>额额。。。此贴的所有操作都是基于 <code>next8</code>
版本进行的。。。<br />
版本对应不上可能导致相关文件找不到，还请各位善用搜索引擎</p>
<span id="more"></span>
<h1 id="可切换模式按钮">可切换模式按钮</h1>
<p><del>参考了这个佬的<a
href="https://haomingzhang.com/hexo_3/">博客</a></del><br />
<del>在路径<code>themes/next/_vendors.yml</code> 下添加
<code>darkmode.js</code> 的cdn</del><br />
<del>然后我在next目录下没有找到 <code>_config.next.yml</code>
但是我添加在 <code>_config.yml</code> 里</del></p>
<p><br></p>
<p>失败了。。。<br />
可能是版本不对，更新给文件删了吧。。。</p>
<hr />
<p>我又找到了另一个佬的<a
href="https://www.techgrow.cn/posts/abf4aee1.html">博客</a><br />
废话我不多说了，有用！<br />
然后如果要自定义可以在这个路径下进行修改<br />
<code>\[root]\node_modules\hexo-next-darkmode\lib</code><br />
root 就是你的博客根目录，其他 npm install 的包也在这里，可以找一找
hh</p>
<h1 id="文章底部添加">文章底部添加</h1>
<p>额原理就是加一个html的div标签<br />
在路径 <code>\themes\next\layout\_macro</code> 中新建
<code>passage-end-tag.swig</code> 文件,并添加以下内容：<br />
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">    &#123;% if not is_index %&#125;</span><br><span class="line">        <span class="tag">&lt;<span class="name">div</span> <span class="attr">style</span>=<span class="string">&quot;text-align:center;color: #ccc;font-size:14px;&quot;</span>&gt;</span>-------------本文结束<span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;fa fa-paw&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span>感谢您的阅读-------------<span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>接着打开<code>\themes\next\layout\_macro\post.swig</code>文件，在post-body
之后， post-footer
之前添加如下画红色部分代码（post-footer之前两个DIV，在END POST
BODY之后的部分）： <figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">  &#123;% if not is_index %&#125;</span><br><span class="line">    &#123;% include &#x27;passage-end-tag.swig&#x27; %&#125;</span><br><span class="line">  &#123;% endif %&#125;</span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>但是我是没有 <code>post.swig</code> 文件的，我操作了
<code>post.njk</code> 文件，同样可以</p>
<p>然后打开主题配置文件(_config.yml),在末尾添加： <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 文章末尾添加“本文结束”标记</span><br><span class="line">passage_end_tag:</span><br><span class="line">  enabled: true</span><br></pre></td></tr></table></figure></p>
<h1 id="把底部-标签换成图标">把底部 # 标签换成图标</h1>
<p>修改模板<code>/themes/next/layout/_macro/post.njk</code> 在尾部找到
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;%- set tag_indicate = &#x27;&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;&#x27; if theme.tag_icon else &#x27;#&#x27; %&#125;</span><br><span class="line"></span><br><span class="line"># 删去 if theme.tag_icon else &#x27;#&#x27; 即可</span><br><span class="line">&#123;%- set tag_indicate = &#x27;&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;&#x27;%&#125;</span><br><span class="line">重新渲染后可正确使用</span><br></pre></td></tr></table></figure></p>
<h1 id="首页折叠">首页折叠</h1>
<p>起因是我觉得每次进主页都直接看全文很麻烦。。。<br />
然后去搜了下压缩结果是静态资源的压缩，在这篇<a
href="https://akilar.top/posts/49b73b87/">博客</a>里<br />
但我其实搜错关键字了hh<br />
歪打正着给博客静态资源压缩了<br />
参考这篇<a
href="https://blog.csdn.net/yueyue200830/article/details/104470646">博客</a>
没想到主页文章折叠在 <code>next</code> 的 <code>_config.yml</code>
文件里就有<br />
不过貌似优先级比较低？在我的<code>markdown</code>生成目录的文章里，如果填在
<code>&lt;!--TOC--&gt;</code> 标签之前就无法折叠了。。。</p>
<h1 id="next文章评论区">next文章评论区</h1>
<p>看了下 <code>next</code> 的 <code>_config.yml</code> 文件<br />
额额最终还是采用了 <code>waline</code>
搭建个人博客（<code>gitalk</code>折腾了半天一直会报
<code>e.toLowerCase is not a function</code>的错，他在GitHub的issue下面是有相关问题的，但是我按照其他人给出的解决方案没有搞定，只能转战
<code>waline</code> 了<br />
waline的参考手册还是很详细的，按照步骤很方便快速地部署完成了</p>
<h2 id="vercel-部署">vercel 部署</h2>
<p>采用了 <code>vercel</code> 自动部署 <code>waline</code><br />
参考文档如下： - <a
href="https://waline.js.org/guide/deploy/vercel.html#%E5%A6%82%E4%BD%95%E9%83%A8%E7%BD%B2">Waline</a></p>
<p>管理界面地址为 https://[your app address]/ui<br />
或者进入你的app中，看页面上方的导航标签有管理可以进入。。。<br />
但是有一个问题就是通过vercel部署访问的速度实在太慢了。。。<br />
之后考虑看看有没有其他办法能够部署到国内</p>
<h2 id="waline-dark">waline dark</h2>
<p>配置好的 waline 是不支持黑夜模式的，看了官方文档但是我没有找到 client
文件，所以直接修改 css 作罢<br />
随后考虑修改 <code>_config.yml</code>
文件中的字段看是否能够修改（？字段几乎都不起作用，奇怪）<br />
最后考虑到之前做的 dark mode按钮，那个是直接覆盖页面的
css，应该也可以修改评论区的css<br />
一查发现佬的文章里已经做了说明。 &gt; 由于暗黑模式切换插件依赖了
Darkmode.js，如果插件不生效，这很有可能是 Darkmode.js 的 CDN
资源失效了（在国内访问被墙）。<br />
&gt; 此时，建议使用暗黑模式切换插件的 libUrl 配置参数来指定可用的 CDN
资源链接，如下所示： &gt; - 使用 Unpkg 免费提供的 CDN 资源 &gt;
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">darkmode_js:</span><br><span class="line"> ...</span><br><span class="line"> libUrl: &#x27;https://unpkg.com/darkmode-js@1.5.7/lib/darkmode-js.min.js&#x27;</span><br></pre></td></tr></table></figure> &gt; - 使用 Jsdelivr 免费提供的 CDN 资源 &gt;
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">darkmode_js:</span><br><span class="line"> ...</span><br><span class="line"> libUrl: &#x27;https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js&#x27;</span><br></pre></td></tr></table></figure></p>
<p>按照佬的方案轻松解决 ^ ^</p>
<h2 id="waline加速">waline加速</h2>
<p>由于<code>vercel</code>在国内被dns污染了所以访问起来不挂梯子是看不到评论区的<br />
参考了网上的一些方法，刚好域名备案下来了，搞一下waline的加速<br />
<br> ！注意，这个操作是要基于已有域名的情况下才能继续进行<br />
我们要做的就是<strong>用已有的博客域名去免费申请一个子域名来代替vercel.app那个被污染的域名。</strong></p>
<ol type="1">
<li>进入域名控制台，找到你的博客域名，添加解析记录
<ol type="1">
<li>记录类型选择 <code>CNAME</code></li>
<li>主机记录填 <code>comment</code>
(可以自定，这一步完成你的二级域名就是 comment + 你的一级域名)</li>
<li>添加记录值为 <code>cname.vercel-dns.com</code></li>
</ol></li>
</ol>
<p>(比如我的域名是 <code>szf.cool</code>，那么操作完，我的二级域名应该是
<code>comment.szf.cool</code>)<br />
<br> 2.
进入vercel控制台，进入你的项目，在<code>setting</code>-<code>Domains</code>下，在输入框中输入你的二级域名
=&gt; add添加<br />
3.
同时修改next的config文件，更换一下<code>serverURL</code>字段即可<br />
4. 这样就可以了，随后部署测试一下评论区是否能够正常访问即可</p>
<p>额额但是在博客的评论区里，power by waline的版本是2.x。。。<br />
在管理页面是 3.x 版本，目前还没出问题，不至于以后会不会有问题。。。</p>
<h1 id="文件跳过渲染">文件跳过渲染</h1>
<p>修改站点配置文件中的 <code>skip_render</code> 配置项。<br />
只有 <code>source</code> 目录下的文件才会发布，因此 Hexo 只渲染 source
目录下的文件。<code>skip_render</code> 参数设置的路径是相对于
<code>source</code> 目录的路径。<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#单个文件</span><br><span class="line">skip_render: hello.html</span><br><span class="line"></span><br><span class="line">#单个文件夹下全部文件</span><br><span class="line">skip_render: test/* </span><br><span class="line"></span><br><span class="line">#单个文件夹下指定类型文件</span><br><span class="line">skip_render: test/*.md  </span><br><span class="line"></span><br><span class="line">#单个文件夹下全部文件以及子目录</span><br><span class="line">skip_render: test/**  </span><br><span class="line"></span><br><span class="line">#跳过多个目录，或者多个文件</span><br><span class="line">skip_render: [&#x27;*.html&#x27;, demo/**, test/*]</span><br></pre></td></tr></table></figure></p>
<h1 id="文章置顶功能">文章置顶功能</h1>
<p>参考这篇<a
href="https://blog.csdn.net/stormdony/article/details/86745805">博客</a><br />
首先修改本地的仓库<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ npm uninstall hexo-generator-index --save</span><br><span class="line">$ npm install hexo-generator-index-pin-top --save</span><br></pre></td></tr></table></figure></p>
<p>然后就可以在文章的顶部信息修改 <code>top</code> 字段了。。。<br />
同时要设置一下置顶的标签 hh</p>
<p>我是在<code>\next\layout\_marco\post.nijk</code> 文件下的
<code>post-meta-container</code>标签中添加的相关代码<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% if post.top %&#125;</span><br><span class="line">  &lt;i class=&quot;fa fa-thumb-tack&quot;&gt;&lt;/i&gt;</span><br><span class="line">  &lt;font color=7D26CD&gt;置顶&lt;/font&gt;</span><br><span class="line">  &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure> 注意缩进 ^ ^<br />
但是这个紫色的颜色不好看，我修改了 font color的值</p>
<h1 id="更新markdown渲染">更新markdown渲染</h1>
<p>额额看花书洋洋洒洒写了点文字，结果没想到markdown的渲染好像不是很行，于是按照教程重新折腾了一下markdown的渲染。。。<br />
教程在<a
href="https://blog.csdn.net/qq_42951560/article/details/123596899">这里</a><br />
笔者又找到一个markdown的依赖包<a
href="https://blog.csdn.net/qq_36667170/article/details/105846999">教程</a></p>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>nexT</tag>
      </tags>
  </entry>
  <entry>
    <title>markdown生成目录</title>
    <url>/2024/04/09/markdown%E7%94%9F%E6%88%90%E7%9B%AE%E5%BD%95/</url>
    <content><![CDATA[<!-- TOC -->
<!-- vscode-markdown-toc -->
<ul>
<li><a href="#test">test</a></li>
<li><a
href="#VSCMarkdownTOC">利用VSC的插件<code>Markdown TOC</code>生成目录</a></li>
<li><a href="#test-1">test</a>
<ul>
<li><a href="#test1">test1</a> <!-- vscode-markdown-toc-config
  numbering=false
  autoSave=true
  /vscode-markdown-toc-config --> <!-- /TOC --></li>
</ul></li>
</ul>
<span id="more"></span>
<h1 id="在hexo中开启侧边栏文章目录">在hexo中开启侧边栏文章目录</h1>
<p>看了网上的一些帖子，好像因为 <code>next</code> 版本不匹配导致<br />
其实好像不用大费周章寻找
<code>_custom.styl</code>（至少我是这样。。。）<br />
只需要在<code>_config.md</code> 下修改 toc 词条即可<br />
这是我的配置<br />
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Table of Contents in the Sidebar</span><br><span class="line"># Front-matter variable (nonsupport wrap expand_all).</span><br><span class="line">toc:</span><br><span class="line">  enable: true</span><br><span class="line">  # Automatically add list number to toc.</span><br><span class="line">  number: true</span><br><span class="line">  # If true, all words will placed on next lines if header width longer then sidebar width.</span><br><span class="line">  wrap: true</span><br><span class="line">  # If true, all level of TOC in a post will be displayed, rather than the activated part of it.</span><br><span class="line">  expand_all: true</span><br><span class="line">  # Maximum heading depth of generated toc.</span><br><span class="line">  max_depth: 3</span><br></pre></td></tr></table></figure> 按照英文指示自行按照喜好修改参数即可hh</p>
<h2 id="test"><a name='test'></a>test</h2>
<blockquote>
<p>test for generate TOC</p>
</blockquote>
<h1 id="markdown中插入目录">markdown中插入目录</h1>
<h2
id="利用vsc的插件markdown-toc生成目录"><a name='VSCMarkdownTOC'></a>利用VSC的插件<code>Markdown TOC</code>生成目录</h2>
<p>直接在VSC的插件里搜索
<code>Markdown TOC</code>，第一个下载最高的插件下载<br />
根据插件给出的使用方法<br />
&gt; 1. <code>ctrl + shift + p</code> 呼出面板 &gt; 2.
将光标移动到你要生成目录的地方 &gt; 3. 输入 <code>Generate</code>
找到命令 <code>Generate TOC for markdown</code> &gt; 4.
选择该命令就可以了。。。 &gt; 5. 可以在他注释的地方修改参数 &gt;
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">numbering=false # 为true则开启标签目录带序号</span><br><span class="line">autoSave=true   # 为true生成目录时自动保存文件</span><br></pre></td></tr></table></figure></p>
<p>不过好像这个插件会自动将你md文件中的标签改成 html 的格式<br />
但是初次生成的时候，好像默认两个参数都是true，我也没找到在哪里修改他的配置文件，所以就怪怪的要生成两次，先生成一次然后修改参数，删掉原来的目录（保存注释），再生成一次他就会按照参数生成一份</p>
<p><br></p>
<p>而且感觉这东西好像不太实用呢，我需要将他生成的目录先放到hexo生成的两个<code>---</code>后面，然后这个插件为啥不支持生成一级文件。。。<br />
此文仅做个记录以后不用了。。。</p>
<h2 id="test-1"><a name='test-1'></a>test</h2>
<blockquote>
<p>test for generate TOC</p>
</blockquote>
<h3 id="test1"><a name='test1'></a>test1</h3>
<blockquote>
<p>test for generate TOC</p>
</blockquote>
<h2 id="typora">typora</h2>
<p>。。。才发现 typora能自动生成目录啊<br />
<code>[TOC]</code>即可。。。<br />
有点 🤡 了呀</p>
]]></content>
      <categories>
        <category>markdown</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo 主题更换</title>
    <url>/2024/04/07/hexo-%E4%B8%BB%E9%A2%98%E6%9B%B4%E6%8D%A2/</url>
    <content><![CDATA[<p>今天折腾一下 hexo 的主题变换 hh</p>
<span id="more"></span>
<p>翻了一下<a
href="https://hexo.io/themes/">hexo主题</a>，看到几个我自己觉得比较简洁还不错的<br />
- <a
href="https://github.com/hooozen/hexo-theme-tranquility">Tranquility</a>
- <a href="https://github.com/Lhcfl/hexo-theme-anatolo">Anatolo</a> - <a
href="https://github.com/jerryc127/hexo-theme-butterfly">butterfly</a> -
... 之后再看看吧 hhh</p>
<hr />
<blockquote>
<p>安装的过程参考了这篇<a
href="https://zhuanlan.zhihu.com/p/618864711">文章</a></p>
</blockquote>
<h1 id="安装-next">安装 next</h1>
<p>在根目录下执行 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/next-theme/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure></p>
<p>下载完成后进入 <code>_config.yml</code> 文件修改
<code>theme</code>，输入 next 即可<br />
然后 hexo 三连就能看到主页主题已经发生变化了</p>
<p>版本查看在
<code>/themes/next/package.json</code>文件的version词条里</p>
<h2 id="安装插件">安装插件</h2>
<h3 id="博客信息">博客信息</h3>
<p>此为在根目录下的总的博客信息，包括
<code>title</code>、<code>subtitle</code> 等等内容</p>
<h3 id="配置-next-主页">配置 next 主页</h3>
<p>进 <code>next</code> 的 <code>_config.yml</code>
文件进行修改注释是不行的，因为他找不到相应的路径<br />
所以要先在根目录下建立相应的文件夹然后再去修改 <code>next</code>
的配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo new page [tags名称] # 比如和注释里相同的 about、tags之类</span><br></pre></td></tr></table></figure>
<p>同理创建其他菜单，然后在 <code>next</code>
的配置文件中进行修改即可...<br />
可以在source里面找到菜单，其实里面就是一些 md
文件，也可以自己进行修改添加内容等</p>
<h3 id="搜索功能">搜索功能</h3>
<p>添加搜索功能与预计阅读时间<br />
需要安装 <code>symbols-count-time</code> 插件<br />
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install hexo-symbols-count-time</span><br></pre></td></tr></table></figure></p>
<h3 id="账户头像">账户头像</h3>
<p>首先要将图片放在 <code>/next/source/images</code> 下<br />
然后修改 <code>next</code>
的配置文件，更改avatar的图片路径为刚刚的路径即可<br />
- rounded 是图片是否被圆形切割 - rotated 是头像是否随鼠标旋转</p>
<h3 id="修改文章间的分割线">修改文章间的分割线</h3>
<p>找到文件
<code>themes/next/source/css/_common/components/post/post-footer.styl</code>
进入修改如下内容 <figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.post-eof</span> &#123;</span><br><span class="line">  <span class="attribute">background</span>: $grey-light;</span><br><span class="line">  <span class="attribute">height</span>: <span class="number">3px</span>;</span><br><span class="line">  <span class="attribute">margin</span>: $post-eof-margin-top auto $post-eof-margin-bottom;</span><br><span class="line">  <span class="attribute">text-align</span>: center;</span><br><span class="line">  <span class="attribute">width</span>: <span class="number">100%</span>;</span><br><span class="line"></span><br><span class="line">  <span class="selector-class">.post-block</span><span class="selector-pseudo">:last-of-type</span> &amp; &#123;</span><br><span class="line">    <span class="attribute">display</span>: none;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> 可以自行根据喜好决定参数大小</p>
<h3 id="next的目录和标签">nexT的目录和标签</h3>
<p>按照之前的步骤，<code>hexo new page</code> 完之后，要在
<code>tags</code> 和 <code>categories</code> 的 <code>index.md</code>
里修改一下 <code>type</code><br />
就是在<code>date</code>下加上<code>type: "tags"</code></p>
<p>以 <code>tags</code> 为例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: tags</span><br><span class="line">date : xxxx</span><br><span class="line">type : &quot;tags&quot;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<p>然后回到<code>_post</code>要推送的笔记下面，在相应文章的标签上加上<code>tags</code>即可<br />
如下所示: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: xxxx</span><br><span class="line">date: xxxx</span><br><span class="line">categories: hexo</span><br><span class="line">tags: # 标签（多标签）</span><br><span class="line">- hexo</span><br><span class="line">- nexT</span><br><span class="line">---</span><br></pre></td></tr></table></figure></p>
<p>然后 <code>hexo</code> 三连即可</p>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>nexT</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo本地博客+云服务器个人博客搭建</title>
    <url>/2024/04/06/hexo%E6%9C%AC%E5%9C%B0%E5%8D%9A%E5%AE%A2+%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p>记录一下本地搭建 <code>hexo</code>
个人博客并部署到云服务器的过程。。。<br />
本地环境是 <code>win11</code> ，云服务器是
<code>Ubuntu 22.04LTS</code></p>
<p>大概的流程是本地写笔记，推送到云服务器然后部署，展示给大家<br />
所以当然也可以用 <code>GitHub.io</code>
去进行部署，这是取决于各位的。。。</p>
<span id="more"></span>
<h1 id="node.js-git">Node.js &amp;&amp; git</h1>
<p><code>Node.js</code> 和 <code>git</code> 是 <code>hexo</code>
安装前的必备插件，所以要提前安装一下这两个，基本上，进官网直接下载一直
next 安装即可。。。</p>
<h2 id="git">git</h2>
<p><a href="https://git-scm.com/download/win">git下载地址</a><br />
可以通过 cmd 命令 <code>git -v</code> 查看 <code>git</code>
版本判断是否成功安装<br />
按需下载即可</p>
<h2 id="node.js">Node.js</h2>
<p><a href="https://nodejs.cn/download/">Nodejs下载地址</a><br />
同样按需下载，没有特殊要求无脑继续就可以了。。<br />
可以在 cmd 窗口中通过 <code>node -v</code> 和 <code>npm -v</code>
命令查看版本（查看是否成功安装了 node）<br />
注意 <code>node</code> 自带 <code>npm</code>
,但是版本和下载路径可能不满足大家的需求</p>
<h3 id="npm更换淘宝镜像源">npm更换淘宝镜像源</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#最新地址 淘宝 NPM 镜像站喊你切换新域名啦!</span></span><br><span class="line">npm config <span class="built_in">set</span> registry https://registry.npmmirror.com</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看当前源</span></span><br><span class="line">npm config get registry </span><br><span class="line"></span><br><span class="line"><span class="comment"># 恢复官方源</span></span><br><span class="line">npm config <span class="built_in">set</span> registry https://registry.npmjs.org</span><br></pre></td></tr></table></figure>
<h3 id="npm更新">npm更新</h3>
<p><a
href="https://juejin.cn/post/7065534944101007391">搜索词条的第一个</a><br />
这里通过 <code>n</code> 包对 <code>Nodejs</code> 进行管理
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">npm install -g n</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看版本</span></span><br><span class="line">n lts <span class="comment"># 长期支持版本</span></span><br><span class="line">n latest <span class="comment"># 最新版本</span></span><br></pre></td></tr></table></figure></p>
<p>其他命令就不展示了，善用搜索引擎 hh</p>
<h1 id="配置-hexo">配置 hexo</h1>
<p>在命令行中输入<br />
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure></p>
<p>找到你要写博客的父目录，比如你想将文件夹放在桌面就取到桌面的路径下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init &lt;folder&gt; // folder为你的博客目录名字</span><br><span class="line"><span class="built_in">cd</span> &lt;folder&gt; // 进入该目录</span><br><span class="line">npm install // 安装依赖</span><br></pre></td></tr></table></figure>
<p>到此，本地博客就已经搭建完成了</p>
<h1 id="将本地博客部署到云服务器中">将本地博客部署到云服务器中</h1>
<p>既然是部署到云服务器，当然需要 <code>ssh</code> 连接，我用的 cmd
下的ssh连接<br />
貌似 win 下已经自带了 openssh
吧，我不太清楚hh，还请有心人自行检索搜索引擎 ^ ^</p>
<h2 id="git-安装">git 安装</h2>
<p>这里我用的阿里云的服务器，他们给的镜像里已经装有了 <code>git</code>
所以就没有安装了。。<br />
既然需要同步，那么自然不能每次都要登录 <code>git</code>
，所以要配置一下免密登录</p>
<h3 id="创建用户并设置密码">1. 创建用户并设置密码</h3>
<p>下面的 <code>username</code>
设置为你喜欢的用户名，并设置一个属于这个账户的密码 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">adduser [username]</span><br><span class="line">passwd [username]</span><br></pre></td></tr></table></figure>
可能不是这个顺序，但是注意看命令行给的提示，看心情补充额外信息吧，只要有用户名密码即可
hh</p>
<h3 id="分配用户权限">2. 分配用户权限</h3>
<p>如果没有 wheel 组就先建立 wheel 组（没有的话直接添加会报错的）
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 建立 wheel 组</span></span><br><span class="line">addgroup wheel</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加刚刚建立的用户到用户组</span></span><br><span class="line">usermod [username] -G wheel</span><br></pre></td></tr></table></figure></p>
<h3 id="本地创建密钥">3. 本地创建密钥</h3>
<p>！！！ 注意是在本地 <code>win11</code>
创建密钥，相当于身份证了，就可以实现免密登录了<br />
在本机终端中输入 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure> 然后无脑回车，得到一个新的密钥
一般来说在你创建的时候命令行会提示你密钥文件的路径，windows电脑一般是C:.ssh（不确定可以百度一下
hh）</p>
<p>复制id_rsa.pub文件中的内容备用。</p>
<h3 id="配置公钥">4. 配置公钥</h3>
<p>回到服务器端，用 <code>su</code> 命令切到你创建的那个用户中
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">su - [username]</span><br></pre></td></tr></table></figure></p>
<p>创建 <code>.ssh</code> 文件夹 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~</span><br><span class="line"><span class="built_in">mkdir</span> .ssh</span><br></pre></td></tr></table></figure></p>
<p>利用 <code>vi</code> 或 <code>vim</code> 新建
<code>authorized_keys</code> 文件 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim .ssh/authorized_keys</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">vi .ssh/authorized_keys</span><br></pre></td></tr></table></figure> 将刚刚
<code>id_rsa.pub</code> 公钥中的内容，复制粘贴到文件里，保存退出。</p>
<h2 id="git-仓库配置">git 仓库配置</h2>
<p>退出用户登录 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">su root</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">按照提示输入你的密码...</span></span><br></pre></td></tr></table></figure></p>
<p>这时应该可以看到是 <code>root</code> 用户，创建 <code>git</code>
目录，并修改目录的所有权和用户权限 <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> /home/git/</span><br><span class="line"><span class="built_in">chown</span> -R [username]:[username] /home/git/   <span class="comment"># 是你刚刚创建的用户名</span></span><br><span class="line"><span class="built_in">chmod</span> -R 755 /home/git/</span><br></pre></td></tr></table></figure></p>
<p>进入目录，建立git仓库，修改权限 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /home/git/</span><br><span class="line">git init --bare blog.git</span><br><span class="line">chown [username]:[username] -R blog.git</span><br></pre></td></tr></table></figure></p>
<p>新建钩子文件，但是要看你具体的 git 版本 我的是
<code>post-update.xxx</code>（文件类型忘了，配置时忘了记录）<br />
需要进入修改添加两行内容 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /home/git/blog.git/hooks/post (然后这里直接按 tab 补全补出来)</span><br></pre></td></tr></table></figure></p>
<p>进入文件后添加 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">git --work-tree=/home/blog --git-dir=/home/git/blog.git checkout -f</span><br></pre></td></tr></table></figure></p>
<p>不着急退出，看一下上面的注释，我的文件里写着要修改文件名为
<code>post-update</code> 才能生效，具体问题具体分析吧，用 rm
命令重命名好了，然后<code>wq</code>保存退出<br />
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rm ./post- (tab 补全)  ./post-update</span><br></pre></td></tr></table></figure></p>
<p>然后修改文件权限 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod +x /home/git/blog.git/hooks/post-update</span><br></pre></td></tr></table></figure></p>
<h2 id="配置-nginx">配置 nginx</h2>
<p>安装 <code>nginx</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">apt-install nginx </span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">同样可以查看版本判断是否安装成功</span></span><br><span class="line">nginx -v</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置开机启动</span></span><br><span class="line">systemctl enable nginx.service</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看 nginx 状态</span></span><br><span class="line">systemctl status nginx.service</span><br></pre></td></tr></table></figure>
<p>修改nginx的默认配置，其中cd后边就是刚刚查到的安装位置，每个人可能都不一样
<code>/usr/local/nginx/conf/nginx.conf</code><br />
我的安装位置是<code>/etc/nginx/nginx.conf</code><br />
在网上我看到两种说法，一种修改 default一种修改
conf，但我个人觉得还是修改conf吧。。。<br />
<a href="https://zhuanlan.zhihu.com/p/158678677">配置 conf
文件</a><br />
<a
href="https://blog.captainz.cc/posts/hexo_nginx.html#%E9%85%8D%E7%BD%AE-Nginx-%E6%89%98%E7%AE%A1%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95">配置
default 文件</a></p>
<p>配置完重启下 <code>nginx</code> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">service nginx restart</span><br></pre></td></tr></table></figure></p>
<h2 id="更改本地-hexo-配置文件">更改本地 hexo 配置文件</h2>
<p>打开你<strong>本地</strong>的hexo博客所在文件里面的配置文件_config.yml<br />
应该在最后的位置 <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: [username]@[公网ip]:[/home/git/blog.git]   #用户名@服务器Ip:git仓库位置</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure></p>
<p>在本地hexo博客根目录下，打开终端，部署<br />
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure></p>
<p>然后访问服务器的 IP 地址应该就可以看到 hexo
已经部署完成了。。。<br />
后续就是善用搜索引擎的过程了。。。</p>
<h1 id="域名配置">域名配置</h1>
<p>但是目前访问博客的时候有个问题，就是网址栏一直有个不安全，这是由于通过http访问<br />
我们需要将其改为 https 访问(https = http + ssl)<br />
所以首先要申请 ssl 证书，然后再去nginx里配置一下<br />
1. 去服务商拿ssl免费证书<br />
我是阿里的服务器，<a
href="https://yundun.console.aliyun.com/?spm=5176.7968328.J_8413632810.1.62ae685bLZTqIi&amp;p=cas&amp;showBuy=1#/certExtend/free/cn-hangzhou">地址</a>在这里<br />
2. 选择免费证书，然后一路系统配置申领就好了<br />
3. 申领结束点击下载 nginx 版本<br />
4. 将证书传到服务器的指定位置(!需要记住)<br />
我放在了 <code>/etc/nginx/conf.d</code>文件夹下 5. 修改
<code>nginx.conf</code> 配置文件内容<br />
注意如果在 conf 文件下修改，要在 http
的域内修改，所以要排查一下"{}"是否闭合，防止漏了hh<br />
添加或者修改<code>server</code>域<br />
这是https的433端口配置<br />
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash">HTTPS的默认访问端口443。</span></span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash">如果未在此处配置HTTPS的默认访问端口，可能会造成Nginx无法启动。</span></span><br><span class="line">  listen 443 ssl;</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash">填写证书绑定的域名</span></span><br><span class="line">  server_name domain_name;</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash">填写证书文件名称</span></span><br><span class="line">  ssl_certificate cert/domain_name.pem;</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash">填写证书私钥文件名称</span></span><br><span class="line">  ssl_certificate_key cert/domain_name.key;</span><br><span class="line">  ssl_session_cache shared:SSL:1m;</span><br><span class="line">  ssl_session_timeout 5m;</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash">自定义设置使用的TLS协议的类型以及加密套件（以下为配置示例，请您自行评估是否需要配置）</span></span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash">TLS协议版本越高，HTTPS通信的安全性越高，但是相较于低版本TLS协议，高版本TLS协议对浏览器的兼容性较差。</span></span><br><span class="line">  ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4;</span><br><span class="line">  ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3;</span><br><span class="line"><span class="meta prompt_">  #</span><span class="language-bash">表示优先使用服务端加密套件。默认开启</span></span><br><span class="line">  ssl_prefer_server_ciphers on;</span><br><span class="line">  location / &#123;</span><br><span class="line">        #配置域名最终向后端发送请求的url地址</span><br><span class="line">        proxy_pass http://127.0.0.1:8008;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<pre><code>这是http的80端口配置

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">      # 配置阿里云域名和监听的80端口</span><br><span class="line">      listen       80;</span><br><span class="line">      server_name  domain_name;</span><br><span class="line">      #charset koi8-r;</span><br><span class="line">      #access_log  logs/host.access.log  main;</span><br><span class="line"></span><br><span class="line">      #将所有HTTP请求通过rewrite指令重定向到HTTPS。</span><br><span class="line">      rewrite ^(.*)$ https://$host$1;</span><br><span class="line">      location / &#123;</span><br><span class="line">          #配置域名最终向后端发送请求的url地址</span><br><span class="line">          proxy_pass http://127.0.0.1:8008;</span><br><span class="line">      &#125;</span><br><span class="line">      #error_page  404              /404.html;</span><br><span class="line">      # redirect server error pages to the static page /50x.html</span><br><span class="line">      #</span><br><span class="line">      error_page   500 502 503 504  /50x.html;</span><br><span class="line">      location = /50x.html &#123;</span><br><span class="line">          root   html;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></code></pre>
<ol start="6" type="1">
<li>配置完依次执行命令 <code>service nginx restart</code> 命令和
<code>nginx -t</code>(或<code>systemctl status nginx.service</code>)命令，查看nginx的运行状态，如果是successful，那么就可以访问一下你的域名，网址栏的<code>不安全</code>字段是否消失并变为小锁了，如果是说明配置完成</li>
</ol>
<h2 id="一次的error记录">一次🤡的Error记录。。。</h2>
<p>但是很抱歉，笔者按照上述流程没有配置成功，在配置转发端口的时候，访问遇到了502
error。。。<br />
然后取消转发配置，能发现ssl证书成功配置<br />
接下来排查一下为啥转发失败了 ^ ^</p>
<hr />
<p>先看一下 <code>proxy_pass</code> 设置，遇到两个问题 - 设置为
<code>127.0.0.1</code> 报502错误 - 设置为 <code>公网IP</code> 报 504
错误</p>
<p>理一下，首先，ssl证书配置成功，说明 443 端口是可以正常访问的<br />
我们的配置思路是，如果通过 http 的 80 端口访问，那么强制改写为 443 走
https 端口访问，然后443端口转发到4000的hexo博客端口</p>
<p>好，那么先排查 80 端口是否能正常访问<br />
&gt; 要先安装 telnet<br />
&gt;
在控制面板-程序-程序和功能-（侧边的）启动或关闭Windows功能-telnet勾选<br />
&gt; 等他安装完即可</p>
<p>在shell中 <code>telnet ip port</code> 如果出现空白页面即可<br />
&gt; 靠，注意是空格不是冒号！！！</p>
<p>ok，80端口能ping通（试了下 443
端口同样能ping通，但是4000端口ping不通<br />
好，那么问题就在4000端口了</p>
<hr />
<p>查看 4000 端口的进程<br />
<code>netstat -nplt</code><br />
发现根本就没有4000端口？！<br />
看到这里突然恍然大悟了，这下🤡了呀<br />
原来咱们部署的原理是，在本地deploy的时候，通过git
hook将文件自动push到服务器的仓库中<br />
然后访问80端口，配置nginx将root修改到博客的静态资源处实现访问。。。<br />
这下是彻底理解咱们的整体部署是在干什么了。。。<br />
哎，蒙头按照教程配置还是一知半解<br />
我也将这次🤡记录在博客上，供大家参考</p>
<hr />
<p>接下来修改 nginx 的配置文件就很清晰了。。。<br />
因为我的博客地址是 <code>/home/blog/</code><br />
直接去conf文件下，首先修改 root 字段的地址<br />
然后 index 字段看一眼没问题，ok 重启，登网站，完美。。。</p>
<p>现在的逻辑是：通过域名访问 80 端口-&gt;转发到 433，433去 root 下面搜
index 给出的文件名<br />
&gt; 终于解决了hhhh</p>
<h1 id="图床搭建">图床搭建</h1>
<p>写博客自然不能少了图片，但是放在 hexo
的文件下，每次推送打包的过程实在是受不了，所以还是选择将图片放在服务器上，搭一个图床好了。。。<br />
参考这篇<a
href="https://blog.csdn.net/m0_51321469/article/details/127340237">文章</a><br />
&gt; 主要的原理是利用 PicGo推送到阿里云的服务器，然后 typora
修改图片索引为 url
地址，这样加载的时候就可以直接在服务器的存储地址上进行搜索，不会占用本地资源了。。。</p>
<h2 id="oss存储">OSS存储</h2>
<p>本文用的是阿里云的OSS存储作为图片的放置，要花点小钱
T.T买个资源包<br />
首先在<a
href="https://ecs.console.aliyun.com/server/region/cn-shanghai#/">阿里云的控制台</a>搜索oss，进入oss控制台，然后点击左侧概览下面的<code>Bucket列表</code>创建一个bucket
- 名称自定 - 地域选择离自己近的就好 -
注意读写权限要是公共读！不然博客无法去读取图片资源</p>
<p>创建完成后，点击下面的资源包搞一个便宜点的资源包（有券的话应该免费 ^
^）<br />
资源购买完成后开始创建类似于私钥的东西<br />
在一开始给出的<a
href="https://ecs.console.aliyun.com/server/region/cn-shanghai#/">控制台</a>中，鼠标移动到右上角的头像下，有个
<code>AccessKey管理</code>，点击进入有弹窗提示，这里选择稍微安全点的子用户（因为拿到你的<code>AccessKey</code>可以控制阿里云账户），然后创建用户
- 登录名称自定 - 显示名称自定 -
访问方式要勾选<code>OpenAPI调用访问</code>！！！</p>
<p>创建完成后给他添加上OSS的权限让这个子用户能够访问OSS（直接点击添加权限，在列表里找一下带OSS的词条即可）<br />
页面先不急关，待会要复制<code>ID</code>和<code>Key</code></p>
<h2 id="picgo配置">PicGo配置</h2>
<p>下载地址： - <a
href="https://github.com/Molunerfinn/PicGo/releases">github</a> - <a
href="https://mirrors.sdu.edu.cn/github-release/Molunerfinn_PicGo/v2.3.1/">山大镜像</a></p>
<p>额额如果是windows直接找到 x64.exe后缀的文件下载安装即可<br />
启动picgo，找到图床设置，选择阿里云OSS： - keyid就是刚刚子用户的id</p>
<ul>
<li><p>keysecret就是他的key</p></li>
<li><p>bucket是bucket名字</p></li>
<li><p>存储区域在</p>
<p><img
src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404251802510.png" /></p></li>
<li><p>存储路径就是你这个bucket下的文件夹，如果没有的话直接就存在bucket里面了</p></li>
</ul>
<p>设置完成可以传一个图片给picgo，然后去阿里的oss刷新一下看看是否成功上传上去了</p>
<h2 id="typora配置">typora配置</h2>
<p>typora下载的资源应该网上一大堆，这个各位善用搜索引擎哈 ^ ^<br />
进入typora点击<code>文件</code>-<code>偏好设置</code>-<code>图像</code></p>
<p><img
src="https://szfmsmdx.oss-cn-hangzhou.aliyuncs.com/blog_pic/202404251800449.png" /></p>
<p>注意要选择上传图片啊！！！</p>
<p>不然好像不行</p>
<p>修改成你自己的picgo的配置即可，然后验证一下看是否能够成功上传即可</p>
<hr />
<p>好了，接下来就是 hexo 三连，测试一下hexo是否能够访问即可<br />
到这里，一个博客总算是大部分都搭好咯（应该吧 hhh</p>
]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>git</tag>
        <tag>nodejs</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
</search>
